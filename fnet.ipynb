{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23613,"status":"ok","timestamp":1680384617928,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"jIrQwmvzlmb0","outputId":"6e66ca64-0cd2-4cab-85e9-2117085a86ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOgkk0I_KShI"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24288,"status":"ok","timestamp":1680384654125,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"Lk20r97ljjE5","outputId":"96f5d439-a8e4-4617-cb00-cb664b1dfd14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":808,"status":"ok","timestamp":1680384654931,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"N4xXSkaJuhTa","outputId":"9dcd8dd9-2ba5-450b-dd84-1e991fc21e2a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  Index File name  \\\n","0           0      0    J1.pdf   \n","1           1      1   J10.pdf   \n","2           2      2   J11.PDF   \n","3           3      3   J12.PDF   \n","4           4      4   J13.PDF   \n","\n","                                             Context   Judgement  \n","0  reportable in the supreme court of india civil...   Ambiguity  \n","1  In the present facts, it is clear that BCCL an...  Respondent  \n","2  It is true that the ARC is not a party-respond...   Ambiguity  \n","3  Hence, it has to be directed that till such am...  Petitioner  \n","4  In view of above, we are inclined to allow thi...  Petitioner  "],"text/html":["\n","  <div id=\"df-0edd4d58-a05f-4a87-81ae-7adb077a63e1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Index</th>\n","      <th>File name</th>\n","      <th>Context</th>\n","      <th>Judgement</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>J1.pdf</td>\n","      <td>reportable in the supreme court of india civil...</td>\n","      <td>Ambiguity</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>J10.pdf</td>\n","      <td>In the present facts, it is clear that BCCL an...</td>\n","      <td>Respondent</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>J11.PDF</td>\n","      <td>It is true that the ARC is not a party-respond...</td>\n","      <td>Ambiguity</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>J12.PDF</td>\n","      <td>Hence, it has to be directed that till such am...</td>\n","      <td>Petitioner</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>J13.PDF</td>\n","      <td>In view of above, we are inclined to allow thi...</td>\n","      <td>Petitioner</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0edd4d58-a05f-4a87-81ae-7adb077a63e1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0edd4d58-a05f-4a87-81ae-7adb077a63e1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0edd4d58-a05f-4a87-81ae-7adb077a63e1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Copy of data.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Vf-FTW7nLrv"},"outputs":[],"source":["import random\n","random.seed(50)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["0b546ab741c5401ab2ebb5cb7239edb5","738ed2d69ed44704a6f1b8bec6cd9d07","2dbf306c5d964bf98990aa90afced468","60042bc33042417aa01ee42a758c1eea","ef20c548afc04748989c2835cd6b9979","9b96b4ef27af4ea2a71c7f8f9592dde7","9c0bfad072c140c9afe6fe780a532ced","a19b124b36124481bc5713f2d99fc9da","7116f7f913dc4a6598d8d4c644215bf4","f85f5d20acee42cc9c490fbaadaffa70","05dbb2dbf8a743eda9ec729ffee58b23","41deb787d6fd4b7bac6af32e91c8082b","0494ce49b6e04589bf5a9731fc2ea9e9","417426d5b5ab46a797b0771ea2d82032","ffe2f8a2f32e41858b3cc73cb6ba8aad","d62a67f26cc84ca1a9310c837f18d69a","67369a8904e84f6684cf51b97f484f30","b1c19e471ab446ec91abfd3961e8c9e3","411e3ba715d24e16ba26272fbebe9830","734b5c15a697423db468983a1e1bb6d8","b65ce9afb75847129203d6ab0ae30582","d3aabdfae99644668793fa81fa552ff5","833a1030e0184e34be4db9f336caf53a","4b0dab58b45d4eb0837cc5c7c4204e01","1e5271fe3ca74764b03d6b4db717c8c4","229af18f50ba4aa8ba29e0e161dc794a","24eaa08a41b34bb6af9d744bfbc4f6b2","95fbf1235fde4918974541dc4863226c","8082a04709eb4a9a995eec624aed22b9","0ed84a1aa62345ec92da87470772008d","e9deaf7f67864a3e8575317f3be089dd","13e6cbb775d34968bad2641229542f61","34cd5fd941ea411f81fbaa5f1d10b156","78a1a92b51e347fc809dc3038bf5127f","b6a337ce9abe4260b584891b6a1e21a3","ee68e1dc384f4facb98fccb1e6b245ba","f73fd42ce25442a98c7b513794f19c75","e638424101e744739323b01ed1279718","414d52322f5c4155af1ab8262626e673","387a3e8a6f614ece9e6b83fb7ffa4961","4b364825b08047469446edcff12f0fbb","f7e259687f25440aa3e90250c135a479","bb4380c894db41b5a947493821554b19","1732bc0e7a894c1eba832ef2e0e0141d"]},"executionInfo":{"elapsed":9519,"status":"ok","timestamp":1680384672035,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"snrOIpdkzJoU","outputId":"99a25049-7436-4f31-d461-015a0446e837"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/430 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b546ab741c5401ab2ebb5cb7239edb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spiece.model:   0%|          | 0.00/708k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41deb787d6fd4b7bac6af32e91c8082b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (‚Ä¶)/main/tokenizer.json:   0%|          | 0.00/1.12M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"833a1030e0184e34be4db9f336caf53a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/201 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a1a92b51e347fc809dc3038bf5127f"}},"metadata":{}}],"source":["#1\n","from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"google/fnet-base\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-Y5O28u_U8x"},"outputs":[],"source":["def process_data(row):\n","\n","    text = row['Context']\n","    text = str(text)\n","    text = ' '.join(text.split())\n","\n","    encodings = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512)\n","\n","    label = 0\n","    if row['Judgement'] == 'Petitioner':\n","        label += 1\n","    if row['Judgement'] == 'Respondent':\n","        label += 2\n","    encodings['label'] = label\n","    encodings['text'] = text\n","\n","    return encodings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1680384680732,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"QFUO-FSd0Tlz","outputId":"b5e883b7-7a55-4f78-f3c7-b89fffc0bf34"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [4, 168, 65, 8, 5250, 4757, 39, 13, 2747, 16678, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1, 'text': 'this is a sample context of the document.'}\n"]}],"source":["print(process_data({\n","    'Context': 'this is a sample context of the document.',\n","    'Judgement': 'Petitioner'\n","}))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EhYQCtyN0Xdx"},"outputs":[],"source":["processed_data = []\n","\n","for i in range(len(df[:1000])):\n","    processed_data.append(process_data(df.iloc[i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXO07LL21Mkr"},"outputs":[],"source":["processed_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szUE_0JYJyg4"},"outputs":[],"source":["#split the data into train and validation data \n","from sklearn.model_selection import train_test_split\n","\n","new_df = pd.DataFrame(processed_data)\n","\n","train_df, valid_df = train_test_split(\n","    new_df,\n","    test_size=0.2,\n","    random_state=2022\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22366,"status":"ok","timestamp":1680384715682,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"k0iCGI9efh4g","outputId":"0bc1cf60-1501-43b0-94a1-8b3bd2358f7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.7)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gRvQbHEQJykY"},"outputs":[],"source":["import pyarrow as pa\n","from datasets import Dataset\n","\n","train_hg = Dataset(pa.Table.from_pandas(train_df))\n","valid_hg = Dataset(pa.Table.from_pandas(valid_df))"]},{"cell_type":"markdown","source":["## using GELU activation function"],"metadata":{"id":"j03x9u59opNq"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3985,"status":"ok","timestamp":1680384764847,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"Q7CZQxx9Jymo","outputId":"00bf372b-ef3a-437a-98d2-01bb96d748e0"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/fnet-base were not used when initializing FNetForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing FNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing FNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of FNetForSequenceClassification were not initialized from the model checkpoint at google/fnet-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#2\n","from transformers import AutoModelForSequenceClassification\n","model1 = AutoModelForSequenceClassification.from_pretrained(\"google/fnet-base\",num_labels=3,hidden_act=\"gelu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["f7ad40b6f76940f9929914345ee51323","2e760805224c4a04861c3b081dd1451c","e0d0a94ac1474ecdb660e6d6393752ab","b54421d1e9c147aa8770c39128faec36","55991e86682c43fdb7e9b5b6ba086462","ff557b0a79374086a09951a52369a7a9","2bf307445446440bac8eb851e0a08d24","3cf66ec6c9b647708ca9b60d755a0f0a","468c02e47be94d019d13c00e38332552","0f13f625667248f7930b271f5e831526","a1e4357931c149f6bb196990e8a16f32"]},"executionInfo":{"elapsed":2122,"status":"ok","timestamp":1680384771312,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"e4ZCTEjXFJy4","outputId":"a10cb365-a6cb-40c7-eb0c-a4496c66dbb0"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-285e81eca82c>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n","  m1 = load_metric('accuracy')\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7ad40b6f76940f9929914345ee51323"}},"metadata":{}}],"source":["from datasets import load_metric\n","m1 = load_metric('accuracy')\n","acc = []\n","\n","\n","def compute_metrics(eval_pred,acc = acc):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    x = m1.compute(predictions=predictions, references=labels)\n","    acc.append(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q8Shl_xiJyqM"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","from transformers.optimization import Adafactor, AdafactorSchedule\n","\n","optimizer = Adafactor(model1.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n","lr_scheduler = AdafactorSchedule(optimizer)\n","training_args = TrainingArguments(output_dir=f\"./out_fold{i}\",\n","                                  overwrite_output_dir = 'True', \n","                                  evaluation_strategy=\"epoch\",\n","                                  eval_steps=10,\n","                                  logging_steps = 10,\n","                                  num_train_epochs=100,\n","                                  logging_dir=\"./logs\",\n","                                  load_best_model_at_end = True,\n","                                  save_strategy= 'epoch'\n","      )\n","\n","trainer = Trainer(\n","    model=model1,\n","    args=training_args,\n","    train_dataset=train_hg,\n","    eval_dataset=valid_hg,\n","    tokenizer=tokenizer,\n","    optimizers=(optimizer, lr_scheduler),\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1209295,"status":"ok","timestamp":1680385991771,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"Efg1P9ZMhcEN","outputId":"3510e875-b2b6-42e5-8d7b-da82788f2dbf"},"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a FNetTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/2000 20:03, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.141800</td>\n","      <td>1.109398</td>\n","      <td>0.475000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.100700</td>\n","      <td>1.044968</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.050200</td>\n","      <td>1.010220</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.039600</td>\n","      <td>0.973372</td>\n","      <td>0.325000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.960500</td>\n","      <td>0.916225</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.882200</td>\n","      <td>0.905098</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.911900</td>\n","      <td>0.900556</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.908400</td>\n","      <td>0.878719</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.850700</td>\n","      <td>0.879112</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.791100</td>\n","      <td>0.859295</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.815600</td>\n","      <td>0.850003</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.698600</td>\n","      <td>0.866840</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.641900</td>\n","      <td>0.783340</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.561300</td>\n","      <td>0.843872</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.518100</td>\n","      <td>0.779522</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.495700</td>\n","      <td>0.730339</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.290400</td>\n","      <td>0.847413</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.238200</td>\n","      <td>0.979363</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.186500</td>\n","      <td>0.839771</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.192700</td>\n","      <td>1.048271</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.128800</td>\n","      <td>0.904922</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.141400</td>\n","      <td>0.941955</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.018300</td>\n","      <td>1.141249</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.011200</td>\n","      <td>1.207094</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.006900</td>\n","      <td>1.177777</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.004300</td>\n","      <td>1.218382</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.003600</td>\n","      <td>1.334553</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.002900</td>\n","      <td>1.368378</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.002500</td>\n","      <td>1.441895</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.001900</td>\n","      <td>1.501732</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.001600</td>\n","      <td>1.545262</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.001300</td>\n","      <td>1.551878</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.001200</td>\n","      <td>1.603096</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.001100</td>\n","      <td>1.668437</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.000900</td>\n","      <td>1.667365</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.000800</td>\n","      <td>1.709476</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.000700</td>\n","      <td>1.724905</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.000600</td>\n","      <td>1.797453</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.000600</td>\n","      <td>1.784172</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.000600</td>\n","      <td>1.842635</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.000400</td>\n","      <td>1.842317</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.000400</td>\n","      <td>1.846963</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.000400</td>\n","      <td>1.906256</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.000400</td>\n","      <td>1.909279</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.000300</td>\n","      <td>1.968797</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.000300</td>\n","      <td>1.960396</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.000300</td>\n","      <td>2.001426</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.000300</td>\n","      <td>2.020353</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.000200</td>\n","      <td>2.046257</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.000200</td>\n","      <td>2.057644</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.000200</td>\n","      <td>2.074358</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.000200</td>\n","      <td>2.112092</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.000200</td>\n","      <td>2.146027</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.000200</td>\n","      <td>2.131676</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.000200</td>\n","      <td>2.224743</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.000100</td>\n","      <td>2.210379</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.000100</td>\n","      <td>2.213410</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.000100</td>\n","      <td>2.249767</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.000100</td>\n","      <td>2.282787</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.000100</td>\n","      <td>2.271726</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.000100</td>\n","      <td>2.283443</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.000100</td>\n","      <td>2.330395</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.000100</td>\n","      <td>2.325042</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.000100</td>\n","      <td>2.343098</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.000100</td>\n","      <td>2.358975</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.000100</td>\n","      <td>2.381990</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.000100</td>\n","      <td>2.412104</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.000100</td>\n","      <td>2.409190</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.000100</td>\n","      <td>2.426409</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.000100</td>\n","      <td>2.448865</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.000100</td>\n","      <td>2.464898</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.000100</td>\n","      <td>2.476990</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.000100</td>\n","      <td>2.506541</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.000100</td>\n","      <td>2.535987</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.000000</td>\n","      <td>2.554718</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.000000</td>\n","      <td>2.566935</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.000000</td>\n","      <td>2.573901</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.000000</td>\n","      <td>2.568258</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.000000</td>\n","      <td>2.569278</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.000000</td>\n","      <td>2.613902</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.000000</td>\n","      <td>2.638268</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.000000</td>\n","      <td>2.684880</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.000000</td>\n","      <td>2.678745</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.000000</td>\n","      <td>2.628435</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.000000</td>\n","      <td>2.655670</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.000000</td>\n","      <td>2.712346</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.000000</td>\n","      <td>2.734877</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.000000</td>\n","      <td>2.764139</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.000000</td>\n","      <td>2.745811</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.000000</td>\n","      <td>2.741660</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.000000</td>\n","      <td>2.781707</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.000000</td>\n","      <td>2.773108</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.000000</td>\n","      <td>2.798511</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.000000</td>\n","      <td>2.820695</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.000000</td>\n","      <td>2.835988</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.000000</td>\n","      <td>2.844715</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.000000</td>\n","      <td>2.845236</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.000000</td>\n","      <td>2.879411</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.000000</td>\n","      <td>2.894305</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000000</td>\n","      <td>2.893273</td>\n","      <td>0.650000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.7303393483161926,\n"," 'eval_accuracy': 0.7,\n"," 'eval_runtime': 0.777,\n"," 'eval_samples_per_second': 51.48,\n"," 'eval_steps_per_second': 6.435,\n"," 'epoch': 100.0}"]},"metadata":{},"execution_count":17}],"source":["trainer.train()\n","trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpDcXRgf_0-X"},"outputs":[],"source":["model1.save_pretrained('./out_fold1990/checkpoint-100/')\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained('./out_fold1990/checkpoint-100/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUdtU028_1Cu"},"outputs":[],"source":["model1.save_pretrained('./model/')\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained('./model/')"]},{"cell_type":"markdown","metadata":{"id":"VP0GSo1EC12i"},"source":["## using RELU activation function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2191,"status":"ok","timestamp":1680386127883,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"Ezho_ylf_1GB","outputId":"9a99a1c2-c20c-4e3b-823d-45da0f3f8dda"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/fnet-base were not used when initializing FNetForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing FNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing FNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of FNetForSequenceClassification were not initialized from the model checkpoint at google/fnet-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#2\n","from transformers import AutoModelForSequenceClassification\n","model1 = AutoModelForSequenceClassification.from_pretrained(\"google/fnet-base\",num_labels=3,hidden_act=\"relu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V7fYksrY_1JG"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","from transformers.optimization import Adafactor, AdafactorSchedule\n","\n","optimizer = Adafactor(model1.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n","lr_scheduler = AdafactorSchedule(optimizer)\n","training_args = TrainingArguments(output_dir=f\"./out_fold{i}\",\n","                                  overwrite_output_dir = 'True', \n","                                  evaluation_strategy=\"epoch\",\n","                                  eval_steps=10,\n","                                  logging_steps = 10,\n","                                  num_train_epochs=100,\n","                                  logging_dir=\"./logs\",\n","                                  load_best_model_at_end = True,\n","                                  save_strategy= 'epoch'\n","      )\n","\n","trainer = Trainer(\n","    model=model1,\n","    args=training_args,\n","    train_dataset=train_hg,\n","    eval_dataset=valid_hg,\n","    tokenizer=tokenizer,\n","    optimizers=(optimizer, lr_scheduler),\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1125639,"status":"ok","timestamp":1680387260142,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"epDi4JY0_1MA","outputId":"21a17ba7-36eb-4f25-dedd-c00f7b106891"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/2000 18:43, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.040300</td>\n","      <td>0.990466</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.976300</td>\n","      <td>0.969151</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.020000</td>\n","      <td>0.945562</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.016200</td>\n","      <td>0.924646</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.944000</td>\n","      <td>0.907862</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.898900</td>\n","      <td>0.902069</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.958100</td>\n","      <td>0.894005</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.939500</td>\n","      <td>0.884211</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.941500</td>\n","      <td>0.875078</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.920700</td>\n","      <td>0.879714</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.936100</td>\n","      <td>0.867450</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.838700</td>\n","      <td>0.882091</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.825800</td>\n","      <td>0.819864</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.794600</td>\n","      <td>0.821372</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.766100</td>\n","      <td>0.816625</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.687300</td>\n","      <td>0.763092</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.650600</td>\n","      <td>0.819075</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.540600</td>\n","      <td>0.887170</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.502100</td>\n","      <td>0.759343</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.377600</td>\n","      <td>0.792553</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.326300</td>\n","      <td>0.813992</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.281900</td>\n","      <td>0.802811</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.246400</td>\n","      <td>0.963161</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.188200</td>\n","      <td>0.729015</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.135500</td>\n","      <td>0.801656</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.084100</td>\n","      <td>0.880209</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.099000</td>\n","      <td>0.989775</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.024600</td>\n","      <td>1.085811</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.011700</td>\n","      <td>1.059241</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.007300</td>\n","      <td>1.146042</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.003900</td>\n","      <td>1.298399</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.002400</td>\n","      <td>1.220914</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.001900</td>\n","      <td>1.278453</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.001600</td>\n","      <td>1.317637</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.001300</td>\n","      <td>1.404415</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.001300</td>\n","      <td>1.462933</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.000900</td>\n","      <td>1.488432</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.000800</td>\n","      <td>1.468752</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.000700</td>\n","      <td>1.517729</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.000600</td>\n","      <td>1.470223</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.000500</td>\n","      <td>1.538509</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.000500</td>\n","      <td>1.580627</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.000400</td>\n","      <td>1.587279</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.000400</td>\n","      <td>1.625816</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.000400</td>\n","      <td>1.700651</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.000300</td>\n","      <td>1.686400</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.000300</td>\n","      <td>1.751990</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.000300</td>\n","      <td>1.759168</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.000200</td>\n","      <td>1.771989</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.000200</td>\n","      <td>1.746984</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.000200</td>\n","      <td>1.792712</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.000200</td>\n","      <td>1.856985</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.000200</td>\n","      <td>1.825129</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.000100</td>\n","      <td>1.828960</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.000100</td>\n","      <td>1.915224</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.000100</td>\n","      <td>1.884301</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.000100</td>\n","      <td>1.857389</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.000100</td>\n","      <td>1.965743</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.000100</td>\n","      <td>1.911764</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.000100</td>\n","      <td>1.954212</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.000100</td>\n","      <td>1.942481</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.000100</td>\n","      <td>1.949954</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.000100</td>\n","      <td>2.034086</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.000100</td>\n","      <td>2.037998</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.000100</td>\n","      <td>2.007225</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.000100</td>\n","      <td>1.989861</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.000100</td>\n","      <td>1.975849</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.000100</td>\n","      <td>2.037614</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.000100</td>\n","      <td>2.023296</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.000100</td>\n","      <td>2.083851</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.000100</td>\n","      <td>2.132805</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.000000</td>\n","      <td>2.079342</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.000000</td>\n","      <td>2.099472</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.000000</td>\n","      <td>2.171758</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.000000</td>\n","      <td>2.160017</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.000000</td>\n","      <td>2.172236</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.000000</td>\n","      <td>2.179954</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.000000</td>\n","      <td>2.176248</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.000000</td>\n","      <td>2.204827</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.000000</td>\n","      <td>2.218904</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.000000</td>\n","      <td>2.234630</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.000000</td>\n","      <td>2.451476</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.000000</td>\n","      <td>2.221506</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.000000</td>\n","      <td>2.288487</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.000000</td>\n","      <td>2.268399</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.000000</td>\n","      <td>2.278571</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.000000</td>\n","      <td>2.270673</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.000000</td>\n","      <td>2.342280</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.000000</td>\n","      <td>2.555447</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.000000</td>\n","      <td>2.444726</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.000000</td>\n","      <td>2.455514</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.000000</td>\n","      <td>2.416745</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.000000</td>\n","      <td>2.426872</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.000000</td>\n","      <td>2.441789</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.000000</td>\n","      <td>2.422808</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.000000</td>\n","      <td>2.479346</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.000000</td>\n","      <td>2.496667</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.000000</td>\n","      <td>2.462446</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.000000</td>\n","      <td>2.441900</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000000</td>\n","      <td>2.502821</td>\n","      <td>0.700000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.7290154695510864,\n"," 'eval_accuracy': 0.75,\n"," 'eval_runtime': 0.7796,\n"," 'eval_samples_per_second': 51.305,\n"," 'eval_steps_per_second': 6.413,\n"," 'epoch': 100.0}"]},"metadata":{},"execution_count":23}],"source":["trainer.train()\n","trainer.evaluate()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2qVw8K_5_1O3","executionInfo":{"status":"ok","timestamp":1680387260934,"user_tz":-330,"elapsed":806,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"}},"outputId":"62151fb2-fe42-4fcb-8cfa-f92fb48c9475","colab":{"base_uri":"https://localhost:8080/","height":141}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:01]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.7290154695510864,\n"," 'eval_accuracy': 0.75,\n"," 'eval_runtime': 0.7337,\n"," 'eval_samples_per_second': 54.52,\n"," 'eval_steps_per_second': 6.815,\n"," 'epoch': 100.0}"]},"metadata":{},"execution_count":24}],"source":["trainer.evaluate()\n"]},{"cell_type":"code","source":["model1.save_pretrained('./model/')\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained('./model/')"],"metadata":{"id":"Ho-K-06lUp4R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xv_ckf51FNge"},"source":["## using SILU activation function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2118,"status":"ok","timestamp":1680387264766,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"npWijIH2_1Rm","outputId":"ff229516-7103-482b-b508-620c42c4962e"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/fnet-base were not used when initializing FNetForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing FNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing FNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of FNetForSequenceClassification were not initialized from the model checkpoint at google/fnet-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#3\n","from transformers import AutoModelForSequenceClassification\n","model1 = AutoModelForSequenceClassification.from_pretrained(\"google/fnet-base\",num_labels=3,hidden_act=\"silu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SlZ3v3iC_1Uq"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","from transformers.optimization import Adafactor, AdafactorSchedule\n","\n","optimizer = Adafactor(model1.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n","lr_scheduler = AdafactorSchedule(optimizer)\n","training_args = TrainingArguments(output_dir=f\"./out_fold{i}\",\n","                                  overwrite_output_dir = 'True', \n","                                  evaluation_strategy=\"epoch\",\n","                                  eval_steps=10,\n","                                  logging_steps = 10,\n","                                  num_train_epochs=100,\n","                                  logging_dir=\"./logs\",\n","                                  load_best_model_at_end = True,\n","                                  save_strategy= 'epoch')\n","\n","trainer = Trainer(\n","    model=model1,\n","    args=training_args,\n","    train_dataset=train_hg,\n","    eval_dataset=valid_hg,\n","    tokenizer=tokenizer,\n","    optimizers=(optimizer, lr_scheduler),\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1198213,"status":"ok","timestamp":1680388462976,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"QoyJSUuT_1XS","outputId":"769c2363-3a1c-40da-f593-e3ebac041ab3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/2000 19:55, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.078800</td>\n","      <td>1.045535</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.030800</td>\n","      <td>0.993410</td>\n","      <td>0.475000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.011600</td>\n","      <td>0.956238</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.987200</td>\n","      <td>0.946850</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.938000</td>\n","      <td>0.908466</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.884300</td>\n","      <td>0.905018</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.961700</td>\n","      <td>0.906823</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.946400</td>\n","      <td>0.894368</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.939400</td>\n","      <td>0.878065</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.896900</td>\n","      <td>0.885524</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.990400</td>\n","      <td>0.880133</td>\n","      <td>0.475000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.888700</td>\n","      <td>0.901941</td>\n","      <td>0.475000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.897100</td>\n","      <td>0.908791</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.815600</td>\n","      <td>0.862509</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.817900</td>\n","      <td>0.901581</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.737100</td>\n","      <td>0.886912</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.686400</td>\n","      <td>0.933659</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.634800</td>\n","      <td>0.964575</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.615800</td>\n","      <td>1.062955</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.436200</td>\n","      <td>1.107288</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.309900</td>\n","      <td>1.223209</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.383600</td>\n","      <td>1.068262</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.179600</td>\n","      <td>1.144959</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.240000</td>\n","      <td>1.310246</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.196400</td>\n","      <td>1.163046</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.085100</td>\n","      <td>1.890149</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.163100</td>\n","      <td>2.224799</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.104700</td>\n","      <td>1.728840</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.341800</td>\n","      <td>2.220235</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.007300</td>\n","      <td>2.427301</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.007500</td>\n","      <td>2.294693</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.056800</td>\n","      <td>2.177737</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.003000</td>\n","      <td>2.771942</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.008300</td>\n","      <td>2.868564</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.054200</td>\n","      <td>2.841138</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.001900</td>\n","      <td>2.539509</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.002100</td>\n","      <td>2.301599</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.008500</td>\n","      <td>2.994218</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.037400</td>\n","      <td>3.334908</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.000900</td>\n","      <td>3.158640</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.039100</td>\n","      <td>3.182471</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.159800</td>\n","      <td>3.048518</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.028800</td>\n","      <td>3.307371</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.000700</td>\n","      <td>3.029914</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.046600</td>\n","      <td>2.637297</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.000800</td>\n","      <td>3.834890</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.000400</td>\n","      <td>3.465035</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.000400</td>\n","      <td>3.382218</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.000300</td>\n","      <td>3.539374</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.000300</td>\n","      <td>3.755282</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.000300</td>\n","      <td>3.638834</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.000300</td>\n","      <td>3.665143</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.014200</td>\n","      <td>2.929917</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.000200</td>\n","      <td>3.753126</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.000200</td>\n","      <td>3.761265</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.000200</td>\n","      <td>3.717266</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.000200</td>\n","      <td>3.825419</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.000200</td>\n","      <td>3.751647</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.000100</td>\n","      <td>3.684802</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.000100</td>\n","      <td>3.666812</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.113200</td>\n","      <td>2.964512</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.306700</td>\n","      <td>3.185084</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.398300</td>\n","      <td>2.099679</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.267700</td>\n","      <td>1.944564</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.124000</td>\n","      <td>2.818748</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.323600</td>\n","      <td>2.034657</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.497900</td>\n","      <td>1.778106</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.121400</td>\n","      <td>3.557531</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.231100</td>\n","      <td>3.526506</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.500800</td>\n","      <td>1.904458</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.351000</td>\n","      <td>2.751162</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.000400</td>\n","      <td>3.099001</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.000400</td>\n","      <td>3.718009</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.000200</td>\n","      <td>3.692613</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.000100</td>\n","      <td>3.786860</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.000100</td>\n","      <td>3.814885</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.000100</td>\n","      <td>3.858397</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.000200</td>\n","      <td>3.728533</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.137200</td>\n","      <td>3.966535</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.214700</td>\n","      <td>2.700322</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.000100</td>\n","      <td>2.906204</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.000100</td>\n","      <td>3.067655</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.000100</td>\n","      <td>3.162631</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.000100</td>\n","      <td>3.207234</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.000100</td>\n","      <td>3.241932</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.081200</td>\n","      <td>2.796225</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.000100</td>\n","      <td>3.043688</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.000100</td>\n","      <td>2.752072</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.000100</td>\n","      <td>2.809277</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.000100</td>\n","      <td>3.298237</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.000100</td>\n","      <td>3.250800</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.000100</td>\n","      <td>3.295444</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.000100</td>\n","      <td>3.370775</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.000100</td>\n","      <td>3.376750</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.000100</td>\n","      <td>3.588844</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.315100</td>\n","      <td>2.352394</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.000100</td>\n","      <td>3.336591</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.000100</td>\n","      <td>3.725365</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.000000</td>\n","      <td>3.851557</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000000</td>\n","      <td>3.927048</td>\n","      <td>0.625000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "]},"metadata":{}}],"source":["trainer.train()\n","trainer.evaluate()\n","model1.save_pretrained('./model/')\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained('./model/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":814,"status":"ok","timestamp":1680388463777,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"xKvH-3odh_c8","outputId":"c3203e4c-b066-4b6a-ff53-e51c7d78cee4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:03]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.8625090718269348,\n"," 'eval_accuracy': 0.625,\n"," 'eval_runtime': 0.7208,\n"," 'eval_samples_per_second': 55.492,\n"," 'eval_steps_per_second': 6.936,\n"," 'epoch': 100.0}"]},"metadata":{},"execution_count":29}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTqaSWdOFMMH"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x7KdMo3UGkoG"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"qJLG5D3KGlI1"},"source":["## using GELU NEW activation function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2238,"status":"ok","timestamp":1680388466011,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"},"user_tz":-330},"id":"_gDJ83X7FMPf","outputId":"dd006233-43e1-4c28-90e2-03b95d5adf3f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/fnet-base were not used when initializing FNetForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing FNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing FNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of FNetForSequenceClassification were not initialized from the model checkpoint at google/fnet-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification\n","model1 = AutoModelForSequenceClassification.from_pretrained(\"google/fnet-base\",num_labels=3,hidden_act=\"gelu_new\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KivNdVxSFMSm"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","from transformers.optimization import Adafactor, AdafactorSchedule\n","\n","optimizer = Adafactor(model1.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n","lr_scheduler = AdafactorSchedule(optimizer)\n","training_args = TrainingArguments(output_dir=f\"./out_fold{i}\",\n","                                  overwrite_output_dir = 'True', \n","                                  evaluation_strategy=\"epoch\",\n","                                  eval_steps=10,\n","                                  logging_steps = 10,\n","                                  num_train_epochs=100,\n","                                  logging_dir=\"./logs\",\n","                                  load_best_model_at_end = True,\n","                                  save_strategy= 'epoch')\n","\n","trainer = Trainer(\n","    model=model1,\n","    args=training_args,\n","    train_dataset=train_hg,\n","    eval_dataset=valid_hg,\n","    tokenizer=tokenizer,\n","    optimizers=(optimizer, lr_scheduler),\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"VRIDNDwKFMVw","executionInfo":{"status":"ok","timestamp":1680389831182,"user_tz":-330,"elapsed":1365173,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"}},"outputId":"320c0124-d451-49bd-c145-77140440cbb1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/2000 22:43, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.104300</td>\n","      <td>1.102506</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.085900</td>\n","      <td>1.060300</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.039600</td>\n","      <td>1.002928</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.986900</td>\n","      <td>0.964974</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.934200</td>\n","      <td>0.922089</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.875200</td>\n","      <td>0.899138</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.930400</td>\n","      <td>0.884763</td>\n","      <td>0.475000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.904600</td>\n","      <td>0.872846</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.856800</td>\n","      <td>0.854871</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.815800</td>\n","      <td>0.854414</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.867800</td>\n","      <td>0.829659</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.719400</td>\n","      <td>0.849453</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.643500</td>\n","      <td>0.771544</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.554600</td>\n","      <td>0.857586</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.537600</td>\n","      <td>0.834672</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.445500</td>\n","      <td>0.831669</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.350800</td>\n","      <td>0.763680</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.281100</td>\n","      <td>0.671055</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.155400</td>\n","      <td>0.771690</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.142500</td>\n","      <td>0.970943</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.093300</td>\n","      <td>0.811181</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.046500</td>\n","      <td>0.962925</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.019600</td>\n","      <td>0.927945</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.009700</td>\n","      <td>1.186588</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.010000</td>\n","      <td>1.115361</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.004500</td>\n","      <td>1.149046</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.003800</td>\n","      <td>0.998617</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.002800</td>\n","      <td>1.053507</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.002400</td>\n","      <td>1.042956</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.002100</td>\n","      <td>1.083253</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.001800</td>\n","      <td>1.043647</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.001500</td>\n","      <td>1.081457</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.001300</td>\n","      <td>1.124385</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.001200</td>\n","      <td>1.159228</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.001000</td>\n","      <td>1.139145</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.000900</td>\n","      <td>1.183106</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.000800</td>\n","      <td>1.149917</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.000700</td>\n","      <td>1.175448</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.000700</td>\n","      <td>1.237611</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.000600</td>\n","      <td>1.256708</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.000500</td>\n","      <td>1.232558</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.000500</td>\n","      <td>1.242356</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.000400</td>\n","      <td>1.299524</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.000400</td>\n","      <td>1.332186</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.000400</td>\n","      <td>1.328639</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.000300</td>\n","      <td>1.279122</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.000300</td>\n","      <td>1.294331</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.000300</td>\n","      <td>1.294604</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.000200</td>\n","      <td>1.318985</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.000200</td>\n","      <td>1.353368</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.000200</td>\n","      <td>1.330472</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.000200</td>\n","      <td>1.413703</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.000200</td>\n","      <td>1.359499</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.000200</td>\n","      <td>1.339106</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.000200</td>\n","      <td>1.364764</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.000100</td>\n","      <td>1.383130</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.000100</td>\n","      <td>1.408703</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.000100</td>\n","      <td>1.426960</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.000100</td>\n","      <td>1.437460</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.000100</td>\n","      <td>1.389389</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.000100</td>\n","      <td>1.426053</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.000100</td>\n","      <td>1.487451</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.000100</td>\n","      <td>1.496514</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.000100</td>\n","      <td>1.519603</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.000100</td>\n","      <td>1.530758</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.000100</td>\n","      <td>1.657663</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.000100</td>\n","      <td>1.569323</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.000100</td>\n","      <td>1.662726</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.000100</td>\n","      <td>1.620549</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.000100</td>\n","      <td>1.641196</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.000000</td>\n","      <td>1.655395</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.000000</td>\n","      <td>1.782086</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.000000</td>\n","      <td>1.815555</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.000000</td>\n","      <td>1.759435</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.000000</td>\n","      <td>1.839219</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.000000</td>\n","      <td>1.802088</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.000000</td>\n","      <td>1.817547</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.000000</td>\n","      <td>1.820786</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.000000</td>\n","      <td>1.809486</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.000000</td>\n","      <td>1.882328</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.000000</td>\n","      <td>1.798726</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.000000</td>\n","      <td>1.856318</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.000000</td>\n","      <td>1.885685</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.000000</td>\n","      <td>1.862928</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.000000</td>\n","      <td>1.784871</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.000000</td>\n","      <td>1.831942</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.000000</td>\n","      <td>1.884755</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.000000</td>\n","      <td>1.921782</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.000000</td>\n","      <td>1.936103</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.000000</td>\n","      <td>1.951059</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.000000</td>\n","      <td>1.936117</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.000000</td>\n","      <td>1.959784</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.000000</td>\n","      <td>1.912889</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.000000</td>\n","      <td>1.956129</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.000000</td>\n","      <td>1.960062</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.000000</td>\n","      <td>2.014503</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.000000</td>\n","      <td>2.001584</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.000000</td>\n","      <td>1.983039</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.000000</td>\n","      <td>1.977407</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000000</td>\n","      <td>2.070960</td>\n","      <td>0.750000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2000, training_loss=0.14645272090390427, metrics={'train_runtime': 1364.5933, 'train_samples_per_second': 11.725, 'train_steps_per_second': 1.466, 'total_flos': 2845462118400000.0, 'train_loss': 0.14645272090390427, 'epoch': 100.0})"]},"metadata":{},"execution_count":32}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQtc9saYFMYo","executionInfo":{"status":"ok","timestamp":1680389834226,"user_tz":-330,"elapsed":3087,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"}},"outputId":"f1fc785e-ae46-41dd-e972-7d2948bc639b","colab":{"base_uri":"https://localhost:8080/","height":37}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:00]\n","    </div>\n","    "]},"metadata":{}}],"source":["trainer.evaluate()\n","model1.save_pretrained('./model/')\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained('./model/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCBsyYbDFMbd","executionInfo":{"status":"ok","timestamp":1680389835664,"user_tz":-330,"elapsed":1448,"user":{"displayName":"Ndstalin Vijayakumar","userId":"00151854773489976868"}},"outputId":"ed4c774a-ddd1-41bf-df93-91d21a0cd115","colab":{"base_uri":"https://localhost:8080/","height":141}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:04]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.671055257320404,\n"," 'eval_accuracy': 0.725,\n"," 'eval_runtime': 0.9579,\n"," 'eval_samples_per_second': 41.758,\n"," 'eval_steps_per_second': 5.22,\n"," 'epoch': 100.0}"]},"metadata":{},"execution_count":34}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqVHcHW4FMeX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EukLNkdlFMhV"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85Y_GmGxFMkL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DguSXJ4_FMnR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qsGDZ1SPFMqV"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["##best model from fnet"],"metadata":{"id":"vpNbS69bpR2E"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RyNisUK7mKSG"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained('./model/') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"troSHIQ5mV9J"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","new_tokenizer = AutoTokenizer.from_pretrained()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnMFzomumcUA","outputId":"ada347cb-3b03-4221-c859-1c48453c807e"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}],"source":["import torch\n","import numpy as np\n","if torch.cuda.is_available():  # Tell PyTorch to use the GPU. \n"," device = torch.device(\"cuda\") \n"," print('There are %d GPU(s) available.' % torch.cuda.device_count()) \n"," print('We will use the GPU:', torch.cuda.get_device_name(0)) # If not...\n","else:\n"," print('No GPU available, using the CPU instead.')\n"," device = torch.device(\"cpu\")\n","model.to(device)\n","def get(text):\n","    encoding = new_tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n","    encoding = {k:v.to(trainer.model.device) for k,v in encoding.items()}\n","\n","    outputs = trainer.model( **encoding)\n","\n","    logits = outputs.logits\n","\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(logits.squeeze().cpu())\n","    probs = probs.detach().numpy()\n","    label = np.argmax(probs, axis=-1)\n","    \n","    if label == 1:\n","        return {\n","            'w': 'Petitioner',\n","            'probability': probs[1]\n","        }\n","    elif label == 2:\n","        return {\n","            'w': 'respondent',\n","            'probability': probs[2]\n","            }\n","    elif label == 0:\n","        return {\n","            'w': 'am',\n","            'probability': probs[0]\n","            }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"PUzfEN2lm9Sp","outputId":"6dd24b21-64e0-43b5-df67-dfc975f5c72f"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Petitioner'"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["a = get('We therefore allow this appeal, set aside the impugned order of the High Court and quash the criminal proceedings of Criminal Complaint No. 1029 of 2015. We clarify that this will not come in the way of instituting appropriate proceedings in future in case the Civil Court comes to the conclusion that the disputed sale deed dated 29.12.2010 is forged. We refrain ourselves from expressing any opinion as regards the genuineness or otherwise of the sale deed in question as this question is wide open before the Civil Court. The Civil Court shall decide the civil suit pending between the parties on its own merits and on the basis of the evidence that may be led by both the sides. It shall be open to the Civil Court to take the opinion of the hand writing expert as regards the signature of the complainant on the disputed sale deed. We clarify that we have passed the aforesaid order in the facts and circumstances of the present case and the same shall not be cited as a precedent.')\n","a['w']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"mc_xktgtnmuD","outputId":"f7ccdd0c-d2ca-4617-86db-3b80749d8adb"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Petitioner'"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["b = get('For the above reasons, we hold that no prejudice has resulted to the respondent on account of not furnishing him the copies of the statements of witnesses. We are satisfied that on account of the said violations it cannot he said that the respondent did not have a fair hearing or that the disciplinary enquiry against him was not a fair enquiry. Accordingly, we allow the appeal and set aside the judgment of the High Court affirming the judgments of the Trial Court and Appellate Court.')\n","b['w']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pEEq68lLp_nD","outputId":"4babc4b6-6db0-4982-a835-8a7fbb5c2c3d"},"outputs":[{"data":{"text/plain":["(79, 5)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["train_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6my3IdpBrDvM","outputId":"8631ddf5-4028-45e6-d830-f605d8e1e050"},"outputs":[{"data":{"text/plain":["(20, 5)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["valid_df.shape"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1hNaXQmg4cOecltLiHVR1Pk6X1RZijvCP","timestamp":1680390514405},{"file_id":"1UkHvdQuTBUxOrsIOAD4CxnFYQV3uWS9T","timestamp":1680374116748}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0b546ab741c5401ab2ebb5cb7239edb5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_738ed2d69ed44704a6f1b8bec6cd9d07","IPY_MODEL_2dbf306c5d964bf98990aa90afced468","IPY_MODEL_60042bc33042417aa01ee42a758c1eea"],"layout":"IPY_MODEL_ef20c548afc04748989c2835cd6b9979"}},"738ed2d69ed44704a6f1b8bec6cd9d07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b96b4ef27af4ea2a71c7f8f9592dde7","placeholder":"‚Äã","style":"IPY_MODEL_9c0bfad072c140c9afe6fe780a532ced","value":"Downloading (‚Ä¶)okenizer_config.json: 100%"}},"2dbf306c5d964bf98990aa90afced468":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a19b124b36124481bc5713f2d99fc9da","max":430,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7116f7f913dc4a6598d8d4c644215bf4","value":430}},"60042bc33042417aa01ee42a758c1eea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f85f5d20acee42cc9c490fbaadaffa70","placeholder":"‚Äã","style":"IPY_MODEL_05dbb2dbf8a743eda9ec729ffee58b23","value":" 430/430 [00:00&lt;00:00, 4.53kB/s]"}},"ef20c548afc04748989c2835cd6b9979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b96b4ef27af4ea2a71c7f8f9592dde7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c0bfad072c140c9afe6fe780a532ced":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a19b124b36124481bc5713f2d99fc9da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7116f7f913dc4a6598d8d4c644215bf4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f85f5d20acee42cc9c490fbaadaffa70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05dbb2dbf8a743eda9ec729ffee58b23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41deb787d6fd4b7bac6af32e91c8082b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0494ce49b6e04589bf5a9731fc2ea9e9","IPY_MODEL_417426d5b5ab46a797b0771ea2d82032","IPY_MODEL_ffe2f8a2f32e41858b3cc73cb6ba8aad"],"layout":"IPY_MODEL_d62a67f26cc84ca1a9310c837f18d69a"}},"0494ce49b6e04589bf5a9731fc2ea9e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67369a8904e84f6684cf51b97f484f30","placeholder":"‚Äã","style":"IPY_MODEL_b1c19e471ab446ec91abfd3961e8c9e3","value":"Downloading spiece.model: 100%"}},"417426d5b5ab46a797b0771ea2d82032":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_411e3ba715d24e16ba26272fbebe9830","max":708295,"min":0,"orientation":"horizontal","style":"IPY_MODEL_734b5c15a697423db468983a1e1bb6d8","value":708295}},"ffe2f8a2f32e41858b3cc73cb6ba8aad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b65ce9afb75847129203d6ab0ae30582","placeholder":"‚Äã","style":"IPY_MODEL_d3aabdfae99644668793fa81fa552ff5","value":" 708k/708k [00:00&lt;00:00, 8.04MB/s]"}},"d62a67f26cc84ca1a9310c837f18d69a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67369a8904e84f6684cf51b97f484f30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1c19e471ab446ec91abfd3961e8c9e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"411e3ba715d24e16ba26272fbebe9830":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"734b5c15a697423db468983a1e1bb6d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b65ce9afb75847129203d6ab0ae30582":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3aabdfae99644668793fa81fa552ff5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"833a1030e0184e34be4db9f336caf53a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b0dab58b45d4eb0837cc5c7c4204e01","IPY_MODEL_1e5271fe3ca74764b03d6b4db717c8c4","IPY_MODEL_229af18f50ba4aa8ba29e0e161dc794a"],"layout":"IPY_MODEL_24eaa08a41b34bb6af9d744bfbc4f6b2"}},"4b0dab58b45d4eb0837cc5c7c4204e01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95fbf1235fde4918974541dc4863226c","placeholder":"‚Äã","style":"IPY_MODEL_8082a04709eb4a9a995eec624aed22b9","value":"Downloading (‚Ä¶)/main/tokenizer.json: 100%"}},"1e5271fe3ca74764b03d6b4db717c8c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ed84a1aa62345ec92da87470772008d","max":1122486,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9deaf7f67864a3e8575317f3be089dd","value":1122486}},"229af18f50ba4aa8ba29e0e161dc794a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13e6cbb775d34968bad2641229542f61","placeholder":"‚Äã","style":"IPY_MODEL_34cd5fd941ea411f81fbaa5f1d10b156","value":" 1.12M/1.12M [00:01&lt;00:00, 1.01MB/s]"}},"24eaa08a41b34bb6af9d744bfbc4f6b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95fbf1235fde4918974541dc4863226c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8082a04709eb4a9a995eec624aed22b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ed84a1aa62345ec92da87470772008d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9deaf7f67864a3e8575317f3be089dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"13e6cbb775d34968bad2641229542f61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34cd5fd941ea411f81fbaa5f1d10b156":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78a1a92b51e347fc809dc3038bf5127f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6a337ce9abe4260b584891b6a1e21a3","IPY_MODEL_ee68e1dc384f4facb98fccb1e6b245ba","IPY_MODEL_f73fd42ce25442a98c7b513794f19c75"],"layout":"IPY_MODEL_e638424101e744739323b01ed1279718"}},"b6a337ce9abe4260b584891b6a1e21a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_414d52322f5c4155af1ab8262626e673","placeholder":"‚Äã","style":"IPY_MODEL_387a3e8a6f614ece9e6b83fb7ffa4961","value":"Downloading (‚Ä¶)cial_tokens_map.json: 100%"}},"ee68e1dc384f4facb98fccb1e6b245ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b364825b08047469446edcff12f0fbb","max":201,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7e259687f25440aa3e90250c135a479","value":201}},"f73fd42ce25442a98c7b513794f19c75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb4380c894db41b5a947493821554b19","placeholder":"‚Äã","style":"IPY_MODEL_1732bc0e7a894c1eba832ef2e0e0141d","value":" 201/201 [00:00&lt;00:00, 9.05kB/s]"}},"e638424101e744739323b01ed1279718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"414d52322f5c4155af1ab8262626e673":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"387a3e8a6f614ece9e6b83fb7ffa4961":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b364825b08047469446edcff12f0fbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7e259687f25440aa3e90250c135a479":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb4380c894db41b5a947493821554b19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1732bc0e7a894c1eba832ef2e0e0141d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7ad40b6f76940f9929914345ee51323":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e760805224c4a04861c3b081dd1451c","IPY_MODEL_e0d0a94ac1474ecdb660e6d6393752ab","IPY_MODEL_b54421d1e9c147aa8770c39128faec36"],"layout":"IPY_MODEL_55991e86682c43fdb7e9b5b6ba086462"}},"2e760805224c4a04861c3b081dd1451c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff557b0a79374086a09951a52369a7a9","placeholder":"‚Äã","style":"IPY_MODEL_2bf307445446440bac8eb851e0a08d24","value":"Downloading builder script: "}},"e0d0a94ac1474ecdb660e6d6393752ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cf66ec6c9b647708ca9b60d755a0f0a","max":1652,"min":0,"orientation":"horizontal","style":"IPY_MODEL_468c02e47be94d019d13c00e38332552","value":1652}},"b54421d1e9c147aa8770c39128faec36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f13f625667248f7930b271f5e831526","placeholder":"‚Äã","style":"IPY_MODEL_a1e4357931c149f6bb196990e8a16f32","value":" 4.21k/? [00:00&lt;00:00, 53.8kB/s]"}},"55991e86682c43fdb7e9b5b6ba086462":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff557b0a79374086a09951a52369a7a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bf307445446440bac8eb851e0a08d24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cf66ec6c9b647708ca9b60d755a0f0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"468c02e47be94d019d13c00e38332552":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f13f625667248f7930b271f5e831526":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1e4357931c149f6bb196990e8a16f32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}