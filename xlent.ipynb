{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jIrQwmvzlmb0","outputId":"fc33ed77-2be7-4a2b-84e0-fa0b5059fe0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOgkk0I_KShI"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lk20r97ljjE5"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"N4xXSkaJuhTa","outputId":"a4ef7345-e8b6-4904-9de1-c6745e8cf543"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  Index File name  \\\n","0           0      0    J1.pdf   \n","1           1      1   J10.pdf   \n","2           2      2   J11.PDF   \n","3           3      3   J12.PDF   \n","4           4      4   J13.PDF   \n","\n","                                             Context   Judgement  \n","0  reportable in the supreme court of india civil...   Ambiguity  \n","1  In the present facts, it is clear that BCCL an...  Respondent  \n","2  It is true that the ARC is not a party-respond...   Ambiguity  \n","3  Hence, it has to be directed that till such am...  Petitioner  \n","4  In view of above, we are inclined to allow thi...  Petitioner  "],"text/html":["\n","  <div id=\"df-66793d81-bd17-4ebc-adb1-26409ceee76d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Index</th>\n","      <th>File name</th>\n","      <th>Context</th>\n","      <th>Judgement</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>J1.pdf</td>\n","      <td>reportable in the supreme court of india civil...</td>\n","      <td>Ambiguity</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>J10.pdf</td>\n","      <td>In the present facts, it is clear that BCCL an...</td>\n","      <td>Respondent</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>J11.PDF</td>\n","      <td>It is true that the ARC is not a party-respond...</td>\n","      <td>Ambiguity</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>J12.PDF</td>\n","      <td>Hence, it has to be directed that till such am...</td>\n","      <td>Petitioner</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>J13.PDF</td>\n","      <td>In view of above, we are inclined to allow thi...</td>\n","      <td>Petitioner</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66793d81-bd17-4ebc-adb1-26409ceee76d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-66793d81-bd17-4ebc-adb1-26409ceee76d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-66793d81-bd17-4ebc-adb1-26409ceee76d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["df = pd.read_csv('/content/Copy of data.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Vf-FTW7nLrv"},"outputs":[],"source":["import random\n","random.seed(50)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["572100a248ad4353bcb44abb9dce810f","2c41af76c8b741579ccae3c7f07cce62","ed89bcde296b436a91bc138cfaa41e33","2f2b2b78a1a043af8d3f34d77542c697","7b55f9eefa7d437f935388626267cbbd","b8437ce3511e4600b330a0b55665bfc8","42ec9c5f25324b10970aa5f02e15b57e","27b8837d94d0433bb4f62380d9c795f1","0d12fa66708649388b9b57492630a473","489b255c11084f91bdb0b5f045d1bfb1","db9be85bb8f644539b0504525cc94e4e","22e132f68fd14ecbadebc0a24b7715d7","f06724e279534b3491e5c625178d9556","15a5a95d93f340cd9224caa554d6d1ae","0b09a170ff1342ffaf7de09396cc3faf","67cc3f52fe1742afa5a37115b9aac48a","d2f252eea5774274926f5c49ac506fde","a78f90cdeafc4f229fbcdf988688b370","813f75748a27433289ed2ab4860cb216","91453b5d353c4f05b2e293a1ff483c2b","9a87ae65e800431b84c3b7aee759b11b","2540aa8e88324b08abca72ecfede1670","0ce82acd1be048ed995bf9771adc6ac7","19bfceef27f249b6a67f35def5068f84","6901474387b748a89d79dd808df5bb00","ad0ed36b341f405daa6a9a82db4153c9","c11f38503f1c4959a6aa2013c507694c","63d65be4e12741fea801a0e0b94a9863","7af95ab6cb7f49e892cd3efdad42647f","0328b740d8a34cdb92a38c914e72225b","4909b594513243578bee141d971d9314","580b55bd4e704350beaf796d3193c4bc","47b0e46782f64bf5aa2548f89c7bd4e1"]},"id":"snrOIpdkzJoU","outputId":"5c135750-6970-4bdf-db65-6966ba4784e4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"572100a248ad4353bcb44abb9dce810f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e132f68fd14ecbadebc0a24b7715d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ce82acd1be048ed995bf9771adc6ac7"}},"metadata":{}}],"source":["#1\n","from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-Y5O28u_U8x"},"outputs":[],"source":["def process_data(row):\n","\n","    text = row['Context']\n","    text = str(text)\n","    text = ' '.join(text.split())\n","\n","    encodings = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512)\n","\n","    label = 0\n","    if row['Judgement'] == 'Petitioner':\n","        label += 1\n","    if row['Judgement'] == 'Respondent':\n","        label += 2\n","    encodings['label'] = label\n","    encodings['text'] = text\n","\n","    return encodings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFUO-FSd0Tlz","outputId":"2657849e-da7b-47a6-c24b-8a1b44f0f91c"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 52, 27, 24, 4561, 3773, 20, 18, 2402, 9, 4, 3], 'token_type_ids': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 1, 'text': 'this is a sample context of the document.'}\n"]}],"source":["print(process_data({\n","    'Context': 'this is a sample context of the document.',\n","    'Judgement': 'Petitioner'\n","}))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EhYQCtyN0Xdx"},"outputs":[],"source":["processed_data = []\n","\n","for i in range(len(df[:1000])):\n","    processed_data.append(process_data(df.iloc[i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXO07LL21Mkr"},"outputs":[],"source":["processed_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szUE_0JYJyg4"},"outputs":[],"source":["#split the data into train and validation data \n","from sklearn.model_selection import train_test_split\n","\n","new_df = pd.DataFrame(processed_data)\n","\n","train_df, valid_df = train_test_split(\n","    new_df,\n","    test_size=0.2,\n","    random_state=2022\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0iCGI9efh4g","outputId":"58581b25-b984-443c-d7da-3d895d91f463"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.7)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gRvQbHEQJykY"},"outputs":[],"source":["import pyarrow as pa\n","from datasets import Dataset\n","\n","train_hg = Dataset(pa.Table.from_pandas(train_df))\n","valid_hg = Dataset(pa.Table.from_pandas(valid_df))"]},{"cell_type":"markdown","source":["## using gelu activation function\n","\n"],"metadata":{"id":"WNAqD8BFF3FA"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["40a232fb3d7b41dc8e5b6f4e7ab5e92b","0dd37452384248209ffe3dd5d043366d","1a79ace2dd92433cbada31925b90fd15","23a05e67f3d24770b5b9ec76b69f1b62","4c85269f8e274162986b97fd2bd2dde3","f6a133ec95e343c68f878faedaffc9ca","9d707611a4f14c8d8a16fca2d04a7934","edf7c022feeb4b508b1093157951df0a","288220395a254f219a6745cb8842c91d","9ec74d75495e457ca70b3e32ad8aa143","d6eed5be00d14fb4822077b2ad957d5c"]},"id":"Q7CZQxx9Jymo","outputId":"183b3cf2-7338-4732-cda8-4bfdc8d2af30"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40a232fb3d7b41dc8e5b6f4e7ab5e92b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#2\n","from transformers import AutoModelForSequenceClassification\n","model1 = AutoModelForSequenceClassification.from_pretrained(\"xlnet-base-cased\",num_labels=3,ff_activation=\"gelu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["63becdd1d560468f9cebea3e18222f12","30f1ddb361d24f9eba766534d7bdb7ec","9c459971618440c4bce4215a293d8e5a","d2a14a835347412b9964a4eef09c9dac","9b561a4b9a0143db82cc5f5c3b225da0","92742d0e54a241acaaff69da103f964e","fff79b5ea7d6441b8251d0882938da4c","a684f3d89f71471181a1ce849e80919e","1a5e42efb89a443f96ec38a0c599cf9f","3b6b92fca7c34134bfd3aba80363116b","56158a2a0f3542a6ac3e4e267967445f"]},"id":"e4ZCTEjXFJy4","outputId":"041d1921-422e-4c61-aacc-25330b8e51bb"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-285e81eca82c>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  m1 = load_metric('accuracy')\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63becdd1d560468f9cebea3e18222f12"}},"metadata":{}}],"source":["from datasets import load_metric\n","m1 = load_metric('accuracy')\n","acc = []\n","\n","\n","def compute_metrics(eval_pred,acc = acc):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    x = m1.compute(predictions=predictions, references=labels)\n","    acc.append(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q8Shl_xiJyqM"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","from transformers.optimization import Adafactor, AdafactorSchedule\n","\n","optimizer = Adafactor(model1.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n","lr_scheduler = AdafactorSchedule(optimizer)\n","training_args = TrainingArguments(output_dir=f\"./out_fold{i}\",\n","                                  overwrite_output_dir = 'True', \n","                                  evaluation_strategy=\"epoch\",\n","                                  eval_steps=10,\n","                                  logging_steps = 10,\n","                                  num_train_epochs=100,\n","                                  logging_dir=\"./logs\",\n","                                  load_best_model_at_end = True,\n","                                  save_strategy= 'epoch'\n","      )\n","\n","trainer = Trainer(\n","    model=model1,\n","    args=training_args,\n","    train_dataset=train_hg,\n","    eval_dataset=valid_hg,\n","    tokenizer=tokenizer,\n","    optimizers=(optimizer, lr_scheduler),\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Efg1P9ZMhcEN","outputId":"d155b32e-26a1-4a34-94d4-679af6a3ad2b"},"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a XLNetTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/2000 1:08:44, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.166900</td>\n","      <td>1.113089</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.091300</td>\n","      <td>0.949915</td>\n","      <td>0.450000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.938600</td>\n","      <td>0.901394</td>\n","      <td>0.450000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.004600</td>\n","      <td>0.885105</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.891800</td>\n","      <td>0.877269</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.813400</td>\n","      <td>0.848370</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.864300</td>\n","      <td>0.791002</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.779300</td>\n","      <td>0.769199</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.712400</td>\n","      <td>0.681772</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.636000</td>\n","      <td>0.788457</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.708000</td>\n","      <td>0.674146</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.504700</td>\n","      <td>0.588331</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.464000</td>\n","      <td>0.547625</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.414000</td>\n","      <td>0.531501</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.374100</td>\n","      <td>0.505057</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.246700</td>\n","      <td>0.509665</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.210600</td>\n","      <td>0.639209</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.177000</td>\n","      <td>0.416140</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.169800</td>\n","      <td>0.761623</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.060500</td>\n","      <td>0.788829</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.057000</td>\n","      <td>0.946811</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.013600</td>\n","      <td>1.248222</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.005600</td>\n","      <td>0.915709</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.001000</td>\n","      <td>0.917576</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.001100</td>\n","      <td>0.979790</td>\n","      <td>0.875000</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.000800</td>\n","      <td>1.172749</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.000400</td>\n","      <td>1.169471</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.000300</td>\n","      <td>1.076145</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.000300</td>\n","      <td>1.069649</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.000200</td>\n","      <td>1.084470</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.000200</td>\n","      <td>1.117067</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.000200</td>\n","      <td>1.201886</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.000100</td>\n","      <td>1.205431</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.000100</td>\n","      <td>1.180492</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.000100</td>\n","      <td>1.210743</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.000100</td>\n","      <td>1.198761</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.000100</td>\n","      <td>1.241498</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.000100</td>\n","      <td>1.247207</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.000100</td>\n","      <td>1.232310</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.000100</td>\n","      <td>1.240694</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.000100</td>\n","      <td>1.349454</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.000100</td>\n","      <td>1.285840</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.000100</td>\n","      <td>1.298928</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.000100</td>\n","      <td>1.308556</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.000100</td>\n","      <td>1.284842</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.001400</td>\n","      <td>2.270423</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.000100</td>\n","      <td>1.644998</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.000000</td>\n","      <td>1.627427</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.091700</td>\n","      <td>1.658737</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.000900</td>\n","      <td>1.851938</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.199000</td>\n","      <td>1.578443</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.000100</td>\n","      <td>1.455505</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.000000</td>\n","      <td>1.867236</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.000000</td>\n","      <td>1.865254</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.000000</td>\n","      <td>1.856591</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.000000</td>\n","      <td>1.869978</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.000000</td>\n","      <td>1.894876</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.000000</td>\n","      <td>1.923374</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.000000</td>\n","      <td>1.891197</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.000000</td>\n","      <td>1.921440</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.000000</td>\n","      <td>1.950763</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.000000</td>\n","      <td>1.963867</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.000000</td>\n","      <td>1.989690</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.000000</td>\n","      <td>2.028693</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.000000</td>\n","      <td>2.046945</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.000000</td>\n","      <td>2.017469</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.000000</td>\n","      <td>2.037047</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.000000</td>\n","      <td>2.064257</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.000000</td>\n","      <td>2.080906</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.000000</td>\n","      <td>2.112532</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.000000</td>\n","      <td>2.136720</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.000000</td>\n","      <td>2.148632</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.000000</td>\n","      <td>2.173089</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.000000</td>\n","      <td>2.194007</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.000000</td>\n","      <td>2.217175</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.000000</td>\n","      <td>2.226493</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.000000</td>\n","      <td>2.246179</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.000000</td>\n","      <td>2.268213</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.000000</td>\n","      <td>2.284892</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.000000</td>\n","      <td>2.297365</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.000000</td>\n","      <td>2.273380</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.000000</td>\n","      <td>2.229464</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.000000</td>\n","      <td>2.055029</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.000000</td>\n","      <td>1.971568</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.000000</td>\n","      <td>1.920087</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.000000</td>\n","      <td>1.909153</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.000000</td>\n","      <td>1.920359</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.000000</td>\n","      <td>1.937158</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.000000</td>\n","      <td>1.969398</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.000000</td>\n","      <td>2.001333</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.000000</td>\n","      <td>2.030246</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.000000</td>\n","      <td>2.047363</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.000000</td>\n","      <td>2.066901</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.000000</td>\n","      <td>2.078387</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.000000</td>\n","      <td>2.098118</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.000000</td>\n","      <td>2.013281</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.000000</td>\n","      <td>2.029420</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.000000</td>\n","      <td>2.045703</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.000000</td>\n","      <td>2.054270</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000000</td>\n","      <td>2.083591</td>\n","      <td>0.775000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:03]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.4161399304866791,\n"," 'eval_accuracy': 0.85,\n"," 'eval_runtime': 4.5961,\n"," 'eval_samples_per_second': 8.703,\n"," 'eval_steps_per_second': 1.088,\n"," 'epoch': 100.0}"]},"metadata":{},"execution_count":21}],"source":["trainer.train()\n","trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpDcXRgf_0-X"},"outputs":[],"source":["model1.save_pretrained('./out_fold1990/checkpoint-100/')\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained('./out_fold1990/checkpoint-100/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUdtU028_1Cu"},"outputs":[],"source":["model1.save_pretrained('./model/')\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained('./model/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T-AV8CUGmhvh"},"outputs":[],"source":["a = get('We therefore allow this appeal, set aside the impugned order of the High Court and quash the criminal proceedings of Criminal Complaint No. 1029 of 2015. We clarify that this will not come in the way of instituting appropriate proceedings in future in case the Civil Court comes to the conclusion that the disputed sale deed dated 29.12.2010 is forged. We refrain ourselves from expressing any opinion as regards the genuineness or otherwise of the sale deed in question as this question is wide open before the Civil Court. The Civil Court shall decide the civil suit pending between the parties on its own merits and on the basis of the evidence that may be led by both the sides. It shall be open to the Civil Court to take the opinion of the hand writing expert as regards the signature of the complainant on the disputed sale deed. We clarify that we have passed the aforesaid order in the facts and circumstances of the present case and the same shall not be cited as a precedent.')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"PUzfEN2lm9Sp","outputId":"cfe4cea8-f16f-4c7d-a6f3-ae1ac19b3f2c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Petitioner'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}],"source":["a['w']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQu6idnmnGiq","outputId":"bd461a08-b19f-4853-ff9e-9f1f276e1d0d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9897279"]},"metadata":{},"execution_count":33}],"source":["a['probability']"]},{"cell_type":"markdown","metadata":{"id":"VP0GSo1EC12i"},"source":["## using RELU activation function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ezho_ylf_1GB","outputId":"e8196775-315b-43ae-a412-3aaad1ffbce4"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#2\n","from transformers import AutoModelForSequenceClassification\n","model1 = AutoModelForSequenceClassification.from_pretrained(\"xlnet-base-cased\",num_labels=3,ff_activation=\"relu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V7fYksrY_1JG"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","from transformers.optimization import Adafactor, AdafactorSchedule\n","\n","optimizer = Adafactor(model1.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n","lr_scheduler = AdafactorSchedule(optimizer)\n","training_args = TrainingArguments(output_dir=f\"./out_fold{i}\",\n","                                  overwrite_output_dir = 'True', \n","                                  evaluation_strategy=\"epoch\",\n","                                  eval_steps=10,\n","                                  logging_steps = 10,\n","                                  num_train_epochs=100,\n","                                  logging_dir=\"./logs\",\n","                                  load_best_model_at_end = True,\n","                                  save_strategy= 'epoch'\n","      )\n","\n","trainer = Trainer(\n","    model=model1,\n","    args=training_args,\n","    train_dataset=train_hg,\n","    eval_dataset=valid_hg,\n","    tokenizer=tokenizer,\n","    optimizers=(optimizer, lr_scheduler),\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"epDi4JY0_1MA","outputId":"d0563f2c-fdaa-4501-b8da-7481f669ceb7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/2000 1:08:24, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.420200</td>\n","      <td>1.467468</td>\n","      <td>0.050000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.316300</td>\n","      <td>1.198295</td>\n","      <td>0.375000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.045600</td>\n","      <td>0.915298</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.005100</td>\n","      <td>0.857110</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.910400</td>\n","      <td>0.826198</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.833800</td>\n","      <td>0.852767</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.910300</td>\n","      <td>0.825955</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.916900</td>\n","      <td>0.772369</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.811800</td>\n","      <td>0.754559</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.782600</td>\n","      <td>0.807029</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.928500</td>\n","      <td>0.751357</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.682200</td>\n","      <td>0.946626</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.653300</td>\n","      <td>0.704769</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.673100</td>\n","      <td>0.998673</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.656100</td>\n","      <td>0.630396</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.551200</td>\n","      <td>0.749167</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.384900</td>\n","      <td>0.762911</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.425000</td>\n","      <td>0.687643</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.254200</td>\n","      <td>0.723386</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.224000</td>\n","      <td>0.828752</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.142300</td>\n","      <td>1.240028</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.108300</td>\n","      <td>1.056121</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.041000</td>\n","      <td>1.320333</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.046700</td>\n","      <td>1.236735</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.031000</td>\n","      <td>1.094878</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.000600</td>\n","      <td>1.161560</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.000400</td>\n","      <td>1.176032</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.000300</td>\n","      <td>1.222616</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.000200</td>\n","      <td>1.307187</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.000200</td>\n","      <td>1.333990</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.001200</td>\n","      <td>1.315147</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.000100</td>\n","      <td>1.422481</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.000100</td>\n","      <td>1.415814</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.000100</td>\n","      <td>1.426693</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.000100</td>\n","      <td>1.577181</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.000100</td>\n","      <td>1.654798</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.000100</td>\n","      <td>1.671970</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.000100</td>\n","      <td>1.670459</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.000100</td>\n","      <td>1.676539</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.000000</td>\n","      <td>1.703452</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.000000</td>\n","      <td>1.730612</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.000000</td>\n","      <td>1.755372</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.000000</td>\n","      <td>1.780988</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.000000</td>\n","      <td>1.778993</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.000000</td>\n","      <td>1.799332</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.000000</td>\n","      <td>1.806090</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.000000</td>\n","      <td>1.837766</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.000000</td>\n","      <td>1.861972</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.000000</td>\n","      <td>1.878929</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.000000</td>\n","      <td>1.892308</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.000000</td>\n","      <td>1.888052</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>1.883496</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.000000</td>\n","      <td>1.866681</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.000000</td>\n","      <td>1.889759</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.000000</td>\n","      <td>1.954125</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.000000</td>\n","      <td>1.964860</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.000000</td>\n","      <td>1.954077</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.000000</td>\n","      <td>1.967871</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.000000</td>\n","      <td>1.967562</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.000000</td>\n","      <td>1.978738</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.000000</td>\n","      <td>1.985483</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.000000</td>\n","      <td>1.981366</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.000000</td>\n","      <td>1.992089</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.000000</td>\n","      <td>1.998967</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.000000</td>\n","      <td>2.035815</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.000000</td>\n","      <td>2.039467</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.000000</td>\n","      <td>2.057843</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.000000</td>\n","      <td>2.059533</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.000000</td>\n","      <td>2.055932</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.000000</td>\n","      <td>2.068568</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.000000</td>\n","      <td>2.071146</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.000000</td>\n","      <td>2.088388</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.000000</td>\n","      <td>2.099777</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.000000</td>\n","      <td>2.091788</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.000000</td>\n","      <td>2.130386</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.000000</td>\n","      <td>2.137938</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.000000</td>\n","      <td>2.148475</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.000000</td>\n","      <td>2.168599</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.000000</td>\n","      <td>2.177935</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.000000</td>\n","      <td>2.177738</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.000000</td>\n","      <td>2.178524</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.000000</td>\n","      <td>2.181866</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.000000</td>\n","      <td>2.183426</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.000000</td>\n","      <td>2.200988</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.000000</td>\n","      <td>2.215008</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.000000</td>\n","      <td>2.220115</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.000000</td>\n","      <td>2.208697</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.000000</td>\n","      <td>2.221733</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.000000</td>\n","      <td>2.231551</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.000000</td>\n","      <td>2.245363</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.000000</td>\n","      <td>2.262535</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.000000</td>\n","      <td>2.266790</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.000000</td>\n","      <td>2.281901</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.000000</td>\n","      <td>2.287445</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.000000</td>\n","      <td>2.293535</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.000000</td>\n","      <td>2.298380</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.000000</td>\n","      <td>2.305107</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.000000</td>\n","      <td>2.310138</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.000000</td>\n","      <td>2.321126</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000000</td>\n","      <td>2.332813</td>\n","      <td>0.825000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:03]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.6303955912590027,\n"," 'eval_accuracy': 0.8,\n"," 'eval_runtime': 4.5691,\n"," 'eval_samples_per_second': 8.754,\n"," 'eval_steps_per_second': 1.094,\n"," 'epoch': 100.0}"]},"metadata":{},"execution_count":40}],"source":["trainer.train()\n","trainer.evaluate()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2qVw8K_5_1O3","outputId":"ab6d022e-ff88-4ace-b66f-76f985499fb4","colab":{"base_uri":"https://localhost:8080/","height":37}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:08]\n","    </div>\n","    "]},"metadata":{}}],"source":["trainer.evaluate()\n","model1.save_pretrained('./model/')\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained('./model/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"krrWjJ7enPK3"},"outputs":[],"source":["b = get('For the above reasons, we hold that no prejudice has resulted to the respondent on account of not furnishing him the copies of the statements of witnesses. We are satisfied that on account of the said violations it cannot he said that the respondent did not have a fair hearing or that the disciplinary enquiry against him was not a fair enquiry. Accordingly, we allow the appeal and set aside the judgment of the High Court affirming the judgments of the Trial Court and Appellate Court.')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"mc_xktgtnmuD","outputId":"e7ecb6f7-be2a-4b38-8271-5a2f4b7e4fa0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Petitioner'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}],"source":["b['w']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GV7wHpTRnpmk","outputId":"e7169de8-f6c6-453e-bef9-75921fbb0c6a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9766848"]},"metadata":{},"execution_count":36}],"source":["b['probability']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5cCUew0BFYb","outputId":"936ffff3-cc55-4bec-f13e-b0e554adfaa7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLNetConfig {\n","  \"_name_or_path\": \"./model/\",\n","  \"architectures\": [\n","    \"XLNetForSequenceClassification\"\n","  ],\n","  \"attn_type\": \"bi\",\n","  \"bi_data\": false,\n","  \"bos_token_id\": 1,\n","  \"clamp_len\": -1,\n","  \"d_head\": 64,\n","  \"d_inner\": 3072,\n","  \"d_model\": 768,\n","  \"dropout\": 0.1,\n","  \"end_n_top\": 5,\n","  \"eos_token_id\": 2,\n","  \"ff_activation\": \"relu\",\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"mem_len\": null,\n","  \"model_type\": \"xlnet\",\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"pad_token_id\": 5,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reuse_len\": null,\n","  \"same_length\": false,\n","  \"start_n_top\": 5,\n","  \"summary_activation\": \"tanh\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"last\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 250\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.27.4\",\n","  \"untie_r\": true,\n","  \"use_mems_eval\": true,\n","  \"use_mems_train\": false,\n","  \"vocab_size\": 32000\n","}"]},"metadata":{},"execution_count":43}],"source":["from transformers import AutoConfig\n","config = AutoConfig.from_pretrained(\"./model/\")\n","config"]},{"cell_type":"markdown","metadata":{"id":"xv_ckf51FNge"},"source":["## using silu activation function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npWijIH2_1Rm","outputId":"a63b58c0-3e98-4926-ed7b-f93c4e376873"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#3\n","from transformers import AutoModelForSequenceClassification\n","model1 = AutoModelForSequenceClassification.from_pretrained(\"xlnet-base-cased\",num_labels=3,ff_activation=\"silu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SlZ3v3iC_1Uq"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","from transformers.optimization import Adafactor, AdafactorSchedule\n","\n","optimizer = Adafactor(model1.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n","lr_scheduler = AdafactorSchedule(optimizer)\n","training_args = TrainingArguments(output_dir=f\"./out_fold{i}\",\n","                                  overwrite_output_dir = 'True', \n","                                  evaluation_strategy=\"epoch\",\n","                                  eval_steps=10,\n","                                  logging_steps = 10,\n","                                  num_train_epochs=100,\n","                                  logging_dir=\"./logs\",\n","                                  load_best_model_at_end = True,\n","                                  save_strategy= 'epoch')\n","\n","trainer = Trainer(\n","    model=model1,\n","    args=training_args,\n","    train_dataset=train_hg,\n","    eval_dataset=valid_hg,\n","    tokenizer=tokenizer,\n","    optimizers=(optimizer, lr_scheduler),\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"QoyJSUuT_1XS","outputId":"5b36f385-6382-4eaa-fb79-793e65d9327e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/2000 1:09:36, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.091500</td>\n","      <td>0.962647</td>\n","      <td>0.450000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.997600</td>\n","      <td>0.915936</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.990800</td>\n","      <td>0.895336</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.056200</td>\n","      <td>0.885144</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.962400</td>\n","      <td>0.841557</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.793500</td>\n","      <td>0.877473</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.961400</td>\n","      <td>0.833459</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.924100</td>\n","      <td>0.802966</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.829500</td>\n","      <td>0.750488</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.831900</td>\n","      <td>0.704533</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.934300</td>\n","      <td>0.697325</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.704100</td>\n","      <td>0.870816</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.681500</td>\n","      <td>0.652880</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.692500</td>\n","      <td>0.897592</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.480800</td>\n","      <td>0.837494</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.562800</td>\n","      <td>0.773348</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.540500</td>\n","      <td>0.822497</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.493100</td>\n","      <td>1.399980</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.435100</td>\n","      <td>0.911100</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.285600</td>\n","      <td>1.015581</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.257900</td>\n","      <td>1.220526</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.388300</td>\n","      <td>1.047722</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.194600</td>\n","      <td>1.302994</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.198200</td>\n","      <td>1.707777</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.070100</td>\n","      <td>1.083073</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.069400</td>\n","      <td>1.180102</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.099900</td>\n","      <td>1.468687</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.102600</td>\n","      <td>1.639674</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.000500</td>\n","      <td>1.419833</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.000300</td>\n","      <td>1.227038</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.000300</td>\n","      <td>1.530811</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.000200</td>\n","      <td>1.545501</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.000200</td>\n","      <td>1.484509</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.000200</td>\n","      <td>1.515843</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.000100</td>\n","      <td>1.522021</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.000100</td>\n","      <td>1.528920</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.000100</td>\n","      <td>1.564126</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.000100</td>\n","      <td>1.591972</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.000100</td>\n","      <td>1.644095</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.000100</td>\n","      <td>1.707074</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.000100</td>\n","      <td>1.700165</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.000100</td>\n","      <td>1.718294</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.000100</td>\n","      <td>1.706990</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.000100</td>\n","      <td>1.695640</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.000100</td>\n","      <td>1.704583</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.000100</td>\n","      <td>1.719517</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.000100</td>\n","      <td>1.719115</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.000000</td>\n","      <td>1.765092</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.000000</td>\n","      <td>1.815650</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.000000</td>\n","      <td>1.811390</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.000000</td>\n","      <td>1.822713</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>1.830971</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.000000</td>\n","      <td>1.853433</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.000000</td>\n","      <td>1.905188</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.000000</td>\n","      <td>1.903713</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.000000</td>\n","      <td>1.908265</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.000000</td>\n","      <td>1.917735</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.898300</td>\n","      <td>0.857014</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.652900</td>\n","      <td>1.176580</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.363300</td>\n","      <td>1.415329</td>\n","      <td>0.550000</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.416600</td>\n","      <td>2.577987</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.221500</td>\n","      <td>2.194524</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.185000</td>\n","      <td>3.525425</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.326600</td>\n","      <td>2.296254</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.000300</td>\n","      <td>2.132264</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.327400</td>\n","      <td>3.031720</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.000200</td>\n","      <td>2.149835</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.000100</td>\n","      <td>2.199548</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.000100</td>\n","      <td>2.263117</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.000100</td>\n","      <td>2.291150</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.000100</td>\n","      <td>2.322697</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.000000</td>\n","      <td>2.343940</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.000000</td>\n","      <td>2.368385</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.000000</td>\n","      <td>2.366720</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.000000</td>\n","      <td>2.382879</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.000000</td>\n","      <td>2.300686</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.000000</td>\n","      <td>2.372418</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.000000</td>\n","      <td>2.422607</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.000000</td>\n","      <td>2.443072</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.000000</td>\n","      <td>2.456815</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.000000</td>\n","      <td>2.465333</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.000000</td>\n","      <td>2.466961</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.000000</td>\n","      <td>2.493171</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.000000</td>\n","      <td>2.502404</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.000000</td>\n","      <td>2.510585</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.000000</td>\n","      <td>2.516804</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.000000</td>\n","      <td>2.531680</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.000000</td>\n","      <td>2.532625</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.000000</td>\n","      <td>2.545561</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.000000</td>\n","      <td>2.558658</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.000000</td>\n","      <td>2.565668</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.000000</td>\n","      <td>2.578576</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.000000</td>\n","      <td>2.578727</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.000000</td>\n","      <td>2.591796</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.000000</td>\n","      <td>2.579324</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.000000</td>\n","      <td>2.586331</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.000000</td>\n","      <td>2.595721</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.000000</td>\n","      <td>2.605964</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.000000</td>\n","      <td>2.610436</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000000</td>\n","      <td>2.617243</td>\n","      <td>0.775000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:03]\n","    </div>\n","    "]},"metadata":{}}],"source":["trainer.train()\n","trainer.evaluate()\n","model1.save_pretrained('./model/')\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained('./model/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"xKvH-3odh_c8","outputId":"9daeb17f-535b-4bc3-c1e7-c3e2bf0d0ff9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:11]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.6528797149658203,\n"," 'eval_accuracy': 0.75,\n"," 'eval_runtime': 4.6029,\n"," 'eval_samples_per_second': 8.69,\n"," 'eval_steps_per_second': 1.086,\n"," 'epoch': 100.0}"]},"metadata":{},"execution_count":49}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTqaSWdOFMMH","outputId":"47e1efe9-a98f-4b2f-b331-841c2056e2a6","colab":{"base_uri":"https://localhost:8080/","height":35}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'respondent'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":51}],"source":["c = get('The next question is the quantum of cost to be imposed. Counsel for the respondent No. 1 was called upon to address on this aspect. He submitted that he had no submissions to offer and will leave it to the Court to pass appropriate order. He stated that respondent No. 1 is not keen on receiving cost. Even so, for the reasons which are recorded in the earlier part of this Judgment, it is obvious that the present Election Petition is unnecessary, frivolous and vexatious. That is the finding reached by me. If it is so, the petitioner will have to be saddled with cost quantified at Rs. 7500/- (Rupees Seven Thousand Five Hundred) to be paid to the High Court Legal Services Committee (as respondent No. 1 is not interested in cost) within eight weeks from today. Accordingly, petition dismissed with cost.')\n","c['w']"]},{"cell_type":"code","source":["c[\"probability\"]"],"metadata":{"id":"XB2QcK1rI6Vn","outputId":"9088c56d-4aeb-4310-b564-d159e30162ae","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8040989"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x7KdMo3UGkoG","outputId":"652c7b94-875c-46ad-b794-40c5f7527fa6","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLNetConfig {\n","  \"_name_or_path\": \"./model/\",\n","  \"architectures\": [\n","    \"XLNetForSequenceClassification\"\n","  ],\n","  \"attn_type\": \"bi\",\n","  \"bi_data\": false,\n","  \"bos_token_id\": 1,\n","  \"clamp_len\": -1,\n","  \"d_head\": 64,\n","  \"d_inner\": 3072,\n","  \"d_model\": 768,\n","  \"dropout\": 0.1,\n","  \"end_n_top\": 5,\n","  \"eos_token_id\": 2,\n","  \"ff_activation\": \"silu\",\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"mem_len\": null,\n","  \"model_type\": \"xlnet\",\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"pad_token_id\": 5,\n","  \"problem_type\": \"single_label_classification\",\n","  \"reuse_len\": null,\n","  \"same_length\": false,\n","  \"start_n_top\": 5,\n","  \"summary_activation\": \"tanh\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"last\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 250\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.27.4\",\n","  \"untie_r\": true,\n","  \"use_mems_eval\": true,\n","  \"use_mems_train\": false,\n","  \"vocab_size\": 32000\n","}"]},"metadata":{},"execution_count":53}],"source":["from transformers import AutoConfig\n","config = AutoConfig.from_pretrained(\"./model/\")\n","config"]},{"cell_type":"code","source":[],"metadata":{"id":"crMF5soRGOXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VZfvndtdJR4o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qJLG5D3KGlI1"},"source":["## using gelu_new activation function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["00cbd8be127140548bcf8584de698f03","a61b7ed4973d4111b02d3659aff1e00e","40f2909bc37f429f9534e3a6025d5ca9","8b50e66cc1af47ea8b318e2659c6433e","fe7abd3c8e534f8baab9791b543008fd","1ae2c2fd287a41919eabea57df239330","0d88868a1716469fb9d6a07cfe622a8f","f220ae0864f6492eb4e66964ae4e5b03","cf61f5b0be3b4cdb9287cdef19e4fd2e","78e4280954f9476596617bf3cbd0c634","3b79368bffd34766b65a15944bc6612f"]},"id":"_gDJ83X7FMPf","outputId":"d0800261-45e6-4527-a912-3f3af57e37c6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00cbd8be127140548bcf8584de698f03"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification\n","model1 = AutoModelForSequenceClassification.from_pretrained(\"xlnet-base-cased\",num_labels=3,ff_activation=\"gelu_new\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KivNdVxSFMSm"},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","from transformers.optimization import Adafactor, AdafactorSchedule\n","\n","optimizer = Adafactor(model1.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n","lr_scheduler = AdafactorSchedule(optimizer)\n","training_args = TrainingArguments(output_dir=f\"./out_fold{i}\",\n","                                  overwrite_output_dir = 'True', \n","                                  evaluation_strategy=\"epoch\",\n","                                  eval_steps=10,\n","                                  logging_steps = 10,\n","                                  num_train_epochs=100,\n","                                  logging_dir=\"./logs\",\n","                                  load_best_model_at_end = True,\n","                                  save_strategy= 'epoch')\n","\n","trainer = Trainer(\n","    model=model1,\n","    args=training_args,\n","    train_dataset=train_hg,\n","    eval_dataset=valid_hg,\n","    tokenizer=tokenizer,\n","    optimizers=(optimizer, lr_scheduler),\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"VRIDNDwKFMVw","outputId":"8a279986-2b7d-4d1d-ea52-51dc672c6bec"},"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a XLNetTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2000/2000 1:10:27, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.040400</td>\n","      <td>0.978389</td>\n","      <td>0.350000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.046100</td>\n","      <td>0.913935</td>\n","      <td>0.450000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.987000</td>\n","      <td>0.873163</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.978800</td>\n","      <td>0.834248</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.913700</td>\n","      <td>0.789957</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.801200</td>\n","      <td>0.785630</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.855200</td>\n","      <td>0.705801</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.744500</td>\n","      <td>0.666850</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.693200</td>\n","      <td>0.587211</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.627100</td>\n","      <td>0.632358</td>\n","      <td>0.700000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.594900</td>\n","      <td>0.547967</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.379800</td>\n","      <td>0.602949</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.342700</td>\n","      <td>0.581782</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.299400</td>\n","      <td>0.571068</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.211000</td>\n","      <td>0.546204</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.127400</td>\n","      <td>0.657674</td>\n","      <td>0.850000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.125800</td>\n","      <td>0.657709</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.053700</td>\n","      <td>0.951348</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.033500</td>\n","      <td>0.970513</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.017800</td>\n","      <td>1.415591</td>\n","      <td>0.725000</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.000900</td>\n","      <td>1.129374</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.001500</td>\n","      <td>1.588996</td>\n","      <td>0.650000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.000600</td>\n","      <td>1.135520</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.000300</td>\n","      <td>1.222112</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.000300</td>\n","      <td>1.237036</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.000200</td>\n","      <td>1.368981</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.000200</td>\n","      <td>1.333000</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.000200</td>\n","      <td>1.328030</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.000200</td>\n","      <td>1.365371</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.000100</td>\n","      <td>1.387286</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.000100</td>\n","      <td>1.451710</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.000100</td>\n","      <td>1.473601</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.000100</td>\n","      <td>1.480902</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.000100</td>\n","      <td>1.521674</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.000100</td>\n","      <td>1.547040</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.000100</td>\n","      <td>1.562819</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.000100</td>\n","      <td>1.594288</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.000100</td>\n","      <td>1.599378</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.000100</td>\n","      <td>1.594173</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.000100</td>\n","      <td>1.674781</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.000000</td>\n","      <td>1.670964</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.000000</td>\n","      <td>1.658326</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.000000</td>\n","      <td>1.666393</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.000000</td>\n","      <td>1.684153</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.000000</td>\n","      <td>1.781147</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.000000</td>\n","      <td>1.794911</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.000000</td>\n","      <td>1.811015</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.000000</td>\n","      <td>1.827942</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.000000</td>\n","      <td>1.831415</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.000000</td>\n","      <td>1.914059</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.000000</td>\n","      <td>1.918462</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.000000</td>\n","      <td>1.925145</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.000000</td>\n","      <td>1.919827</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.000000</td>\n","      <td>1.927859</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.000000</td>\n","      <td>1.905991</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.000000</td>\n","      <td>1.925592</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.000000</td>\n","      <td>1.986167</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.000000</td>\n","      <td>1.996133</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.000000</td>\n","      <td>1.990754</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.000000</td>\n","      <td>2.006400</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.000000</td>\n","      <td>2.023098</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.000000</td>\n","      <td>2.005688</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.000000</td>\n","      <td>2.050569</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.000000</td>\n","      <td>2.056230</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.000000</td>\n","      <td>2.074646</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.000000</td>\n","      <td>2.067161</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.000000</td>\n","      <td>2.083099</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.000000</td>\n","      <td>2.097085</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.000000</td>\n","      <td>2.074212</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.000000</td>\n","      <td>2.122001</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.000000</td>\n","      <td>2.120142</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.000000</td>\n","      <td>2.152226</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.000000</td>\n","      <td>2.187436</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.000000</td>\n","      <td>2.177316</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.000000</td>\n","      <td>2.224431</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.000000</td>\n","      <td>2.200550</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.000000</td>\n","      <td>2.252174</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.000000</td>\n","      <td>2.239287</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.000000</td>\n","      <td>2.251389</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.000000</td>\n","      <td>2.227431</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.000000</td>\n","      <td>2.256685</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.000000</td>\n","      <td>2.295631</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.000000</td>\n","      <td>2.290396</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.000000</td>\n","      <td>2.288604</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.000000</td>\n","      <td>2.311385</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.000000</td>\n","      <td>2.302677</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.000000</td>\n","      <td>2.311651</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.000000</td>\n","      <td>2.344823</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.000000</td>\n","      <td>2.335808</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.000000</td>\n","      <td>2.371313</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.000000</td>\n","      <td>2.339242</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.000000</td>\n","      <td>2.346080</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.000000</td>\n","      <td>2.369468</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.000000</td>\n","      <td>2.363361</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.000000</td>\n","      <td>2.386705</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.000000</td>\n","      <td>2.397421</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.000000</td>\n","      <td>2.400201</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.000000</td>\n","      <td>2.392885</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.000000</td>\n","      <td>2.414662</td>\n","      <td>0.775000</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.000000</td>\n","      <td>2.428455</td>\n","      <td>0.775000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2000, training_loss=0.11069929456732189, metrics={'train_runtime': 4231.545, 'train_samples_per_second': 3.781, 'train_steps_per_second': 0.473, 'total_flos': 4558122270720000.0, 'train_loss': 0.11069929456732189, 'epoch': 100.0})"]},"metadata":{},"execution_count":16}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQtc9saYFMYo","colab":{"base_uri":"https://localhost:8080/","height":37},"outputId":"905a869a-9cc8-42e8-b411-2d4bf55bcea3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:03]\n","    </div>\n","    "]},"metadata":{}}],"source":["trainer.evaluate()\n","model1.save_pretrained('./model/')\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained('./model/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCBsyYbDFMbd","colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"02cd690b-c51c-466d-a479-f660a7771b07"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:11]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.5462040901184082,\n"," 'eval_accuracy': 0.825,\n"," 'eval_runtime': 4.705,\n"," 'eval_samples_per_second': 8.502,\n"," 'eval_steps_per_second': 1.063,\n"," 'epoch': 100.0}"]},"metadata":{},"execution_count":18}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqVHcHW4FMeX"},"outputs":[],"source":["d = get('In view of the aforesaid discussions I answer the substantial question of law so framed in this appeal in negative and against the defendants/respondents and consequently, the appeal stands allowed and the impugned judgment and decree dated 15.02.99 passed by the learned first Appellant Court in Title Appeal No. 17/89 stands reversed and the judgment and decree passed by the learned Trial Court in Title Suit No. 11/82 stands restored.')\n","d['w']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EukLNkdlFMhV"},"outputs":[],"source":["d[\"probability\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85Y_GmGxFMkL"},"outputs":[],"source":["from transformers import AutoConfig\n","config = AutoConfig.from_pretrained(\"./model/\")\n","config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DguSXJ4_FMnR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qsGDZ1SPFMqV"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RyNisUK7mKSG"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained('./model/') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"troSHIQ5mV9J"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","new_tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3k-IMyxTCV1P"},"outputs":[],"source":["o = new_tokenizer(\"We therefore allow this appeal, set aside the impugned order of the High Court and quash the criminal proceedings of Criminal Complaint No. 1029 of 2015. We clarify that this will not come in the way of instituting appropriate proceedings in future in case the Civil Court comes to the conclusion that the disputed sale deed dated 29.12.2010 is forged. We refrain ourselves from expressing any opinion as regards the genuineness or otherwise of the sale deed in question as this question is wide open before the Civil Court. The Civil Court shall decide the civil suit pending between the parties on its own merits and on the basis of the evidence that may be led by both the sides. It shall be open to the Civil Court to take the opinion of the hand writing expert as regards the signature of the complainant on the disputed sale deed. We clarify that we have passed the aforesaid order in the facts and circumstances of the present case and the same shall not be cited as a precedent.\", return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n","\n","o.items()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pEEq68lLp_nD","outputId":"91e60815-5e43-43bc-849b-a80359368d86"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(160, 5)"]},"metadata":{},"execution_count":44}],"source":["train_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6my3IdpBrDvM","outputId":"5008ba7f-853e-4eec-faa0-69032bc7b085"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(40, 5)"]},"metadata":{},"execution_count":45}],"source":["valid_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xl709RPcrcNn"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"CEuP7gSXFWCZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## get function is used for final prediction"],"metadata":{"id":"ZWSFKBOCFWq5"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnMFzomumcUA","outputId":"946ceb4b-cf3f-415b-e1a0-c8b1aafd471c"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}],"source":["import torch\n","import numpy as np\n","if torch.cuda.is_available():  # Tell PyTorch to use the GPU. \n"," device = torch.device(\"cuda\") \n"," print('There are %d GPU(s) available.' % torch.cuda.device_count()) \n"," print('We will use the GPU:', torch.cuda.get_device_name(0)) # If not...\n","else:\n"," print('No GPU available, using the CPU instead.')\n"," device = torch.device(\"cpu\")\n","model.to(device)\n","def get(text):\n","    encoding = new_tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n","    encoding = {k:v.to(trainer.model.device) for k,v in encoding.items()}\n","\n","    outputs = trainer.model( **encoding)\n","\n","    logits = outputs.logits\n","\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(logits.squeeze().cpu())\n","    probs = probs.detach().numpy()\n","    label = np.argmax(probs, axis=-1)\n","    \n","    if label == 1:\n","        return {\n","            'w': 'Petitioner',\n","            'probability': probs[1]\n","        }\n","    elif label == 2:\n","        return {\n","            'w': 'respondent',\n","            'probability': probs[2]\n","            }\n","    elif label == 0:\n","        return {\n","            'w': 'am',\n","            'probability': probs[0]\n","            }"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"40a232fb3d7b41dc8e5b6f4e7ab5e92b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0dd37452384248209ffe3dd5d043366d","IPY_MODEL_1a79ace2dd92433cbada31925b90fd15","IPY_MODEL_23a05e67f3d24770b5b9ec76b69f1b62"],"layout":"IPY_MODEL_4c85269f8e274162986b97fd2bd2dde3"}},"0dd37452384248209ffe3dd5d043366d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6a133ec95e343c68f878faedaffc9ca","placeholder":"​","style":"IPY_MODEL_9d707611a4f14c8d8a16fca2d04a7934","value":"Downloading pytorch_model.bin: 100%"}},"1a79ace2dd92433cbada31925b90fd15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_edf7c022feeb4b508b1093157951df0a","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_288220395a254f219a6745cb8842c91d","value":467042463}},"23a05e67f3d24770b5b9ec76b69f1b62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ec74d75495e457ca70b3e32ad8aa143","placeholder":"​","style":"IPY_MODEL_d6eed5be00d14fb4822077b2ad957d5c","value":" 467M/467M [00:05&lt;00:00, 84.5MB/s]"}},"4c85269f8e274162986b97fd2bd2dde3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6a133ec95e343c68f878faedaffc9ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d707611a4f14c8d8a16fca2d04a7934":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edf7c022feeb4b508b1093157951df0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"288220395a254f219a6745cb8842c91d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ec74d75495e457ca70b3e32ad8aa143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6eed5be00d14fb4822077b2ad957d5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"572100a248ad4353bcb44abb9dce810f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c41af76c8b741579ccae3c7f07cce62","IPY_MODEL_ed89bcde296b436a91bc138cfaa41e33","IPY_MODEL_2f2b2b78a1a043af8d3f34d77542c697"],"layout":"IPY_MODEL_7b55f9eefa7d437f935388626267cbbd"}},"2c41af76c8b741579ccae3c7f07cce62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8437ce3511e4600b330a0b55665bfc8","placeholder":"​","style":"IPY_MODEL_42ec9c5f25324b10970aa5f02e15b57e","value":"Downloading (…)lve/main/config.json: 100%"}},"ed89bcde296b436a91bc138cfaa41e33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27b8837d94d0433bb4f62380d9c795f1","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d12fa66708649388b9b57492630a473","value":760}},"2f2b2b78a1a043af8d3f34d77542c697":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_489b255c11084f91bdb0b5f045d1bfb1","placeholder":"​","style":"IPY_MODEL_db9be85bb8f644539b0504525cc94e4e","value":" 760/760 [00:00&lt;00:00, 9.18kB/s]"}},"7b55f9eefa7d437f935388626267cbbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8437ce3511e4600b330a0b55665bfc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42ec9c5f25324b10970aa5f02e15b57e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27b8837d94d0433bb4f62380d9c795f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d12fa66708649388b9b57492630a473":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"489b255c11084f91bdb0b5f045d1bfb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db9be85bb8f644539b0504525cc94e4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22e132f68fd14ecbadebc0a24b7715d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f06724e279534b3491e5c625178d9556","IPY_MODEL_15a5a95d93f340cd9224caa554d6d1ae","IPY_MODEL_0b09a170ff1342ffaf7de09396cc3faf"],"layout":"IPY_MODEL_67cc3f52fe1742afa5a37115b9aac48a"}},"f06724e279534b3491e5c625178d9556":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2f252eea5774274926f5c49ac506fde","placeholder":"​","style":"IPY_MODEL_a78f90cdeafc4f229fbcdf988688b370","value":"Downloading (…)ve/main/spiece.model: 100%"}},"15a5a95d93f340cd9224caa554d6d1ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_813f75748a27433289ed2ab4860cb216","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91453b5d353c4f05b2e293a1ff483c2b","value":798011}},"0b09a170ff1342ffaf7de09396cc3faf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a87ae65e800431b84c3b7aee759b11b","placeholder":"​","style":"IPY_MODEL_2540aa8e88324b08abca72ecfede1670","value":" 798k/798k [00:01&lt;00:00, 720kB/s]"}},"67cc3f52fe1742afa5a37115b9aac48a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2f252eea5774274926f5c49ac506fde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a78f90cdeafc4f229fbcdf988688b370":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"813f75748a27433289ed2ab4860cb216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91453b5d353c4f05b2e293a1ff483c2b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a87ae65e800431b84c3b7aee759b11b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2540aa8e88324b08abca72ecfede1670":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ce82acd1be048ed995bf9771adc6ac7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19bfceef27f249b6a67f35def5068f84","IPY_MODEL_6901474387b748a89d79dd808df5bb00","IPY_MODEL_ad0ed36b341f405daa6a9a82db4153c9"],"layout":"IPY_MODEL_c11f38503f1c4959a6aa2013c507694c"}},"19bfceef27f249b6a67f35def5068f84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63d65be4e12741fea801a0e0b94a9863","placeholder":"​","style":"IPY_MODEL_7af95ab6cb7f49e892cd3efdad42647f","value":"Downloading (…)/main/tokenizer.json: 100%"}},"6901474387b748a89d79dd808df5bb00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0328b740d8a34cdb92a38c914e72225b","max":1382015,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4909b594513243578bee141d971d9314","value":1382015}},"ad0ed36b341f405daa6a9a82db4153c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_580b55bd4e704350beaf796d3193c4bc","placeholder":"​","style":"IPY_MODEL_47b0e46782f64bf5aa2548f89c7bd4e1","value":" 1.38M/1.38M [00:01&lt;00:00, 1.04MB/s]"}},"c11f38503f1c4959a6aa2013c507694c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63d65be4e12741fea801a0e0b94a9863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7af95ab6cb7f49e892cd3efdad42647f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0328b740d8a34cdb92a38c914e72225b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4909b594513243578bee141d971d9314":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"580b55bd4e704350beaf796d3193c4bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47b0e46782f64bf5aa2548f89c7bd4e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63becdd1d560468f9cebea3e18222f12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30f1ddb361d24f9eba766534d7bdb7ec","IPY_MODEL_9c459971618440c4bce4215a293d8e5a","IPY_MODEL_d2a14a835347412b9964a4eef09c9dac"],"layout":"IPY_MODEL_9b561a4b9a0143db82cc5f5c3b225da0"}},"30f1ddb361d24f9eba766534d7bdb7ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92742d0e54a241acaaff69da103f964e","placeholder":"​","style":"IPY_MODEL_fff79b5ea7d6441b8251d0882938da4c","value":"Downloading builder script: "}},"9c459971618440c4bce4215a293d8e5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a684f3d89f71471181a1ce849e80919e","max":1652,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a5e42efb89a443f96ec38a0c599cf9f","value":1652}},"d2a14a835347412b9964a4eef09c9dac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b6b92fca7c34134bfd3aba80363116b","placeholder":"​","style":"IPY_MODEL_56158a2a0f3542a6ac3e4e267967445f","value":" 4.21k/? [00:00&lt;00:00, 177kB/s]"}},"9b561a4b9a0143db82cc5f5c3b225da0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92742d0e54a241acaaff69da103f964e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fff79b5ea7d6441b8251d0882938da4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a684f3d89f71471181a1ce849e80919e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a5e42efb89a443f96ec38a0c599cf9f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b6b92fca7c34134bfd3aba80363116b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56158a2a0f3542a6ac3e4e267967445f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00cbd8be127140548bcf8584de698f03":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a61b7ed4973d4111b02d3659aff1e00e","IPY_MODEL_40f2909bc37f429f9534e3a6025d5ca9","IPY_MODEL_8b50e66cc1af47ea8b318e2659c6433e"],"layout":"IPY_MODEL_fe7abd3c8e534f8baab9791b543008fd"}},"a61b7ed4973d4111b02d3659aff1e00e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ae2c2fd287a41919eabea57df239330","placeholder":"​","style":"IPY_MODEL_0d88868a1716469fb9d6a07cfe622a8f","value":"Downloading pytorch_model.bin: 100%"}},"40f2909bc37f429f9534e3a6025d5ca9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f220ae0864f6492eb4e66964ae4e5b03","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf61f5b0be3b4cdb9287cdef19e4fd2e","value":467042463}},"8b50e66cc1af47ea8b318e2659c6433e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78e4280954f9476596617bf3cbd0c634","placeholder":"​","style":"IPY_MODEL_3b79368bffd34766b65a15944bc6612f","value":" 467M/467M [00:05&lt;00:00, 85.4MB/s]"}},"fe7abd3c8e534f8baab9791b543008fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ae2c2fd287a41919eabea57df239330":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d88868a1716469fb9d6a07cfe622a8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f220ae0864f6492eb4e66964ae4e5b03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf61f5b0be3b4cdb9287cdef19e4fd2e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78e4280954f9476596617bf3cbd0c634":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b79368bffd34766b65a15944bc6612f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}